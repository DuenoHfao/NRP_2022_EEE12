{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import warnings\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('Oxford_Battery_Degradation_Dataset_1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['__header__', '__version__', '__globals__', 'Cell1', 'Cell2', 'Cell3', 'Cell4', 'Cell5', 'Cell6', 'Cell7', 'Cell8'])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "input_data = [\n",
    "    [[], []],\n",
    "    [[], []],\n",
    "    [[], []],\n",
    "    [[], []],\n",
    "    [[], []],\n",
    "    [[], []],\n",
    "    [[], []],\n",
    "    [[], []]\n",
    "]\n",
    "\n",
    "CELL_SIZE = [83, 78, 82, 52, 51, 51, 82, 82]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "for i in range(0, 8):\n",
    "    cell_num = \"Cell{}\".format(i + 1)\n",
    "    for j in range(0, CELL_SIZE[i]):\n",
    "        cyc_num = \"cyc{:04d}\".format(j * 100)\n",
    "        try:\n",
    "            curr = mat[cell_num][0][cyc_num][0][0][\"C1ch\"][0][0]['q'][0][-1][0]\n",
    "        except ValueError:\n",
    "            curr = float(\"NaN\")\n",
    "        input_data[i][0].append(j)\n",
    "        input_data[i][1].append(curr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.        ]\n",
      "  [0.95075689]\n",
      "  [0.92671186]\n",
      "  [0.91225103]\n",
      "  [0.88756713]\n",
      "  [0.87015102]\n",
      "  [0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]]\n",
      "\n",
      " [[0.95075689]\n",
      "  [0.92671186]\n",
      "  [0.91225103]\n",
      "  [0.88756713]\n",
      "  [0.87015102]\n",
      "  [0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]]\n",
      "\n",
      " [[0.92671186]\n",
      "  [0.91225103]\n",
      "  [0.88756713]\n",
      "  [0.87015102]\n",
      "  [0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]]\n",
      "\n",
      " [[0.91225103]\n",
      "  [0.88756713]\n",
      "  [0.87015102]\n",
      "  [0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]]\n",
      "\n",
      " [[0.88756713]\n",
      "  [0.87015102]\n",
      "  [0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]]\n",
      "\n",
      " [[0.87015102]\n",
      "  [0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]]\n",
      "\n",
      " [[0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]]\n",
      "\n",
      " [[0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]]\n",
      "\n",
      " [[0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]]\n",
      "\n",
      " [[0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]]\n",
      "\n",
      " [[0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]]\n",
      "\n",
      " [[0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]]\n",
      "\n",
      " [[0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]]\n",
      "\n",
      " [[0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]]\n",
      "\n",
      " [[0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]]\n",
      "\n",
      " [[0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]]\n",
      "\n",
      " [[0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]]\n",
      "\n",
      " [[0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]]\n",
      "\n",
      " [[0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]]\n",
      "\n",
      " [[0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]]\n",
      "\n",
      " [[0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]]\n",
      "\n",
      " [[0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]]\n",
      "\n",
      " [[0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]]\n",
      "\n",
      " [[0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]]\n",
      "\n",
      " [[0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]]\n",
      "\n",
      " [[0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]]\n",
      "\n",
      " [[0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]]\n",
      "\n",
      " [[0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]]\n",
      "\n",
      " [[0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]]\n",
      "\n",
      " [[0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]]\n",
      "\n",
      " [[0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]]\n",
      "\n",
      " [[0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]]\n",
      "\n",
      " [[0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]]\n",
      "\n",
      " [[0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]]\n",
      "\n",
      " [[0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]]\n",
      "\n",
      " [[0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]]\n",
      "\n",
      " [[0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]]\n",
      "\n",
      " [[0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]]\n",
      "\n",
      " [[0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]]\n",
      "\n",
      " [[0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]]\n",
      "\n",
      " [[0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]]\n",
      "\n",
      " [[0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]]\n",
      "\n",
      " [[0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]]\n",
      "\n",
      " [[0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]]\n",
      "\n",
      " [[0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]]\n",
      "\n",
      " [[0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]]\n",
      "\n",
      " [[0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]]\n",
      "\n",
      " [[0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]]\n",
      "\n",
      " [[0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]]\n",
      "\n",
      " [[0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]]\n",
      "\n",
      " [[0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]]\n",
      "\n",
      " [[0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]]\n",
      "\n",
      " [[0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]]\n",
      "\n",
      " [[0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]]\n",
      "\n",
      " [[0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]]\n",
      "\n",
      " [[0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]]\n",
      "\n",
      " [[0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]]\n",
      "\n",
      " [[0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]]\n",
      "\n",
      " [[0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]]\n",
      "\n",
      " [[0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]]\n",
      "\n",
      " [[0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]]\n",
      "\n",
      " [[0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]]\n",
      "\n",
      " [[0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]]\n",
      "\n",
      " [[0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]]\n",
      "\n",
      " [[0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]]\n",
      "\n",
      " [[0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]]\n",
      "\n",
      " [[0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]]\n",
      "\n",
      " [[0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]\n",
      "  [0.04783169]]\n",
      "\n",
      " [[0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]\n",
      "  [0.04783169]\n",
      "  [0.04171994]]\n",
      "\n",
      " [[0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]\n",
      "  [0.04783169]\n",
      "  [0.04171994]\n",
      "  [0.02701237]]\n",
      "\n",
      " [[0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]\n",
      "  [0.04783169]\n",
      "  [0.04171994]\n",
      "  [0.02701237]\n",
      "  [0.02709591]]\n",
      "\n",
      " [[0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]\n",
      "  [0.04783169]\n",
      "  [0.04171994]\n",
      "  [0.02701237]\n",
      "  [0.02709591]\n",
      "  [0.01972158]]\n",
      "\n",
      " [[0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]\n",
      "  [0.04783169]\n",
      "  [0.04171994]\n",
      "  [0.02701237]\n",
      "  [0.02709591]\n",
      "  [0.01972158]\n",
      "  [0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "\n",
    "for i in range(0, 5):\n",
    "    df_input = pd.DataFrame(input_data[i]).transpose()\n",
    "    df_input = df_input.rename(columns={0: \"cycle\", 1: \"q_value\"})\n",
    "    df_input['interpolate_spline'] = df_input['q_value'].interpolate(option='spline')\n",
    "    df_input['soh'] = df_input['interpolate_spline'] / 740\n",
    "\n",
    "    df_input = df_input.drop(\"cycle\", axis=1)\n",
    "    df_input = df_input.drop(\"q_value\", axis=1)\n",
    "    df_input = df_input.drop(\"interpolate_spline\", axis=1)\n",
    "\n",
    "    sc = MinMaxScaler()\n",
    "    label_sc = MinMaxScaler()\n",
    "    data = sc.fit_transform(df_input.values)\n",
    "    label_sc.fit(df_input.iloc[:, 0].values.reshape(-1, 1))\n",
    "\n",
    "    lookback = 10\n",
    "    inputs = np.zeros((len(data) - lookback, lookback, df_input.shape[1]))\n",
    "    labels = np.zeros(len(data) - lookback)\n",
    "\n",
    "    for i in range(lookback, len(data)):\n",
    "        inputs[i - lookback] = data[i - lookback:i]\n",
    "        labels[i - lookback] = data[i, 0]\n",
    "    inputs = inputs.reshape(-1, lookback, df_input.shape[1])\n",
    "    labels = labels.reshape(-1, 1)\n",
    "\n",
    "    if (count < 5):\n",
    "        if len(train_x) == 0:\n",
    "            train_x = inputs[:]\n",
    "            print(train_x)\n",
    "            train_y = labels[:]\n",
    "        else:\n",
    "            train_x = np.concatenate((train_x, inputs[:]))\n",
    "            train_y = np.concatenate((train_y, labels[:]))\n",
    "    else:\n",
    "        test_x = inputs\n",
    "        test_y = labels\n",
    "\n",
    "    count = count + 1\n",
    "\n",
    "    # test_portion = int(0.2 * len(inputs))\n",
    "    #\n",
    "    # if len(train_x) == 0:\n",
    "    #     train_x = inputs[:-test_portion]\n",
    "    #     train_y = labels[:-test_portion]\n",
    "    # else:\n",
    "    #     train_x = np.concatenate((train_x, inputs[:-test_portion]))\n",
    "    #     train_y = np.concatenate((train_y, labels[:-test_portion]))\n",
    "    #\n",
    "    # if len(test_x) == 0:\n",
    "    #     test_x = inputs[-test_portion:]\n",
    "    #     test_y = labels[-test_portion:]\n",
    "    # else:\n",
    "    #     test_x = np.concatenate((test_x, inputs[-test_portion:]))\n",
    "    #     test_y = np.concatenate((test_y, labels[-test_portion:]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "(255, 10, 1)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_x).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "(255, 1)"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_y).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "(41, 10, 1)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_x).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:, -1]))\n",
    "        return out, h\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def train(train_loader, learn_rate, hidden_dim=256, EPOCHS=100, model_type=\"GRU\"):\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "\n",
    "    model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        start_time = time.process_time()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            counter += 1\n",
    "            h = h.data\n",
    "            model.zero_grad()\n",
    "\n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter,\n",
    "                                                                                       len(train_loader),\n",
    "                                                                                       avg_loss / counter))\n",
    "        current_time = time.process_time()\n",
    "        print(\"Epoch {}/{} Done, Total Loss: {}\".format(epoch, EPOCHS, avg_loss / len(train_loader)))\n",
    "        print(\"Total Time Elapsed: {} seconds\".format(str(current_time - start_time)))\n",
    "        epoch_times.append(current_time - start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def evaluate(model, test_x, test_y, label_scalers):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.process_time()\n",
    "\n",
    "    inp = torch.from_numpy(np.array(test_x))\n",
    "    labs = torch.from_numpy(np.array(test_y))\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    outputs.append(label_sc.inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "    targets.append(label_sc.inverse_transform(labs.numpy()).reshape(-1))\n",
    "\n",
    "    print(\"Evaluation Time: {}\".format(str(time.process_time() - start_time)))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += np.mean(abs(outputs[i] - targets[i]) / (targets[i] + outputs[i]) / 2) / len(outputs)\n",
    "    print(\"sMAPE: {}%\".format(sMAPE * 100))\n",
    "    return outputs, targets, sMAPE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training of GRU model\n",
      "Epoch 1......Step: 1/7....... Average Loss for Epoch: 0.1566334217786789\n",
      "Epoch 1......Step: 2/7....... Average Loss for Epoch: 0.14693795144557953\n",
      "Epoch 1......Step: 3/7....... Average Loss for Epoch: 0.11922642836968105\n",
      "Epoch 1......Step: 4/7....... Average Loss for Epoch: 0.10395742580294609\n",
      "Epoch 1......Step: 5/7....... Average Loss for Epoch: 0.09553886279463768\n",
      "Epoch 1......Step: 6/7....... Average Loss for Epoch: 0.08826310684283574\n",
      "Epoch 1......Step: 7/7....... Average Loss for Epoch: 0.08207065186330251\n",
      "Epoch 1/100 Done, Total Loss: 0.08207065186330251\n",
      "Total Time Elapsed: 1.15625 seconds\n",
      "Epoch 2......Step: 1/7....... Average Loss for Epoch: 0.03877151012420654\n",
      "Epoch 2......Step: 2/7....... Average Loss for Epoch: 0.044488925486803055\n",
      "Epoch 2......Step: 3/7....... Average Loss for Epoch: 0.04567007223765055\n",
      "Epoch 2......Step: 4/7....... Average Loss for Epoch: 0.04715811647474766\n",
      "Epoch 2......Step: 5/7....... Average Loss for Epoch: 0.044696193933486936\n",
      "Epoch 2......Step: 6/7....... Average Loss for Epoch: 0.04203232439855734\n",
      "Epoch 2......Step: 7/7....... Average Loss for Epoch: 0.039223666701998026\n",
      "Epoch 2/100 Done, Total Loss: 0.039223666701998026\n",
      "Total Time Elapsed: 1.171875 seconds\n",
      "Epoch 3......Step: 1/7....... Average Loss for Epoch: 0.018908312544226646\n",
      "Epoch 3......Step: 2/7....... Average Loss for Epoch: 0.022662969306111336\n",
      "Epoch 3......Step: 3/7....... Average Loss for Epoch: 0.02292575811346372\n",
      "Epoch 3......Step: 4/7....... Average Loss for Epoch: 0.023445749655365944\n",
      "Epoch 3......Step: 5/7....... Average Loss for Epoch: 0.02179804351180792\n",
      "Epoch 3......Step: 6/7....... Average Loss for Epoch: 0.0194119355486085\n",
      "Epoch 3......Step: 7/7....... Average Loss for Epoch: 0.017703335266560316\n",
      "Epoch 3/100 Done, Total Loss: 0.017703335266560316\n",
      "Total Time Elapsed: 1.109375 seconds\n",
      "Epoch 4......Step: 1/7....... Average Loss for Epoch: 0.007619435898959637\n",
      "Epoch 4......Step: 2/7....... Average Loss for Epoch: 0.006266053533181548\n",
      "Epoch 4......Step: 3/7....... Average Loss for Epoch: 0.005113471920291583\n",
      "Epoch 4......Step: 4/7....... Average Loss for Epoch: 0.004151728324359283\n",
      "Epoch 4......Step: 5/7....... Average Loss for Epoch: 0.005545891518704593\n",
      "Epoch 4......Step: 6/7....... Average Loss for Epoch: 0.0059005019526618225\n",
      "Epoch 4......Step: 7/7....... Average Loss for Epoch: 0.005443126245933984\n",
      "Epoch 4/100 Done, Total Loss: 0.005443126245933984\n",
      "Total Time Elapsed: 1.0 seconds\n",
      "Epoch 5......Step: 1/7....... Average Loss for Epoch: 0.004849128425121307\n",
      "Epoch 5......Step: 2/7....... Average Loss for Epoch: 0.0060611560475081205\n",
      "Epoch 5......Step: 3/7....... Average Loss for Epoch: 0.005577873593817155\n",
      "Epoch 5......Step: 4/7....... Average Loss for Epoch: 0.004664469423005357\n",
      "Epoch 5......Step: 5/7....... Average Loss for Epoch: 0.003977239388041199\n",
      "Epoch 5......Step: 6/7....... Average Loss for Epoch: 0.0038077220281896493\n",
      "Epoch 5......Step: 7/7....... Average Loss for Epoch: 0.00368705004387136\n",
      "Epoch 5/100 Done, Total Loss: 0.00368705004387136\n",
      "Total Time Elapsed: 1.046875 seconds\n",
      "Epoch 6......Step: 1/7....... Average Loss for Epoch: 0.0017920939717441797\n",
      "Epoch 6......Step: 2/7....... Average Loss for Epoch: 0.0018285854021087289\n",
      "Epoch 6......Step: 3/7....... Average Loss for Epoch: 0.0018139435366416972\n",
      "Epoch 6......Step: 4/7....... Average Loss for Epoch: 0.0020170433854218572\n",
      "Epoch 6......Step: 5/7....... Average Loss for Epoch: 0.002005703025497496\n",
      "Epoch 6......Step: 6/7....... Average Loss for Epoch: 0.0019703335322750113\n",
      "Epoch 6......Step: 7/7....... Average Loss for Epoch: 0.0020004697975569536\n",
      "Epoch 6/100 Done, Total Loss: 0.0020004697975569536\n",
      "Total Time Elapsed: 1.078125 seconds\n",
      "Epoch 7......Step: 1/7....... Average Loss for Epoch: 0.000867131631821394\n",
      "Epoch 7......Step: 2/7....... Average Loss for Epoch: 0.00099755241535604\n",
      "Epoch 7......Step: 3/7....... Average Loss for Epoch: 0.0010342983296141028\n",
      "Epoch 7......Step: 4/7....... Average Loss for Epoch: 0.0009937801369233057\n",
      "Epoch 7......Step: 5/7....... Average Loss for Epoch: 0.0009120503324083984\n",
      "Epoch 7......Step: 6/7....... Average Loss for Epoch: 0.000952769274590537\n",
      "Epoch 7......Step: 7/7....... Average Loss for Epoch: 0.0009400195974324431\n",
      "Epoch 7/100 Done, Total Loss: 0.0009400195974324431\n",
      "Total Time Elapsed: 0.9375 seconds\n",
      "Epoch 8......Step: 1/7....... Average Loss for Epoch: 0.0006151252309791744\n",
      "Epoch 8......Step: 2/7....... Average Loss for Epoch: 0.000909296068130061\n",
      "Epoch 8......Step: 3/7....... Average Loss for Epoch: 0.0009519228672919174\n",
      "Epoch 8......Step: 4/7....... Average Loss for Epoch: 0.0008441862446488813\n",
      "Epoch 8......Step: 5/7....... Average Loss for Epoch: 0.0009147721459157765\n",
      "Epoch 8......Step: 6/7....... Average Loss for Epoch: 0.0008966035481231908\n",
      "Epoch 8......Step: 7/7....... Average Loss for Epoch: 0.0008340690027190638\n",
      "Epoch 8/100 Done, Total Loss: 0.0008340690027190638\n",
      "Total Time Elapsed: 1.125 seconds\n",
      "Epoch 9......Step: 1/7....... Average Loss for Epoch: 0.0006847617914900184\n",
      "Epoch 9......Step: 2/7....... Average Loss for Epoch: 0.000948096567299217\n",
      "Epoch 9......Step: 3/7....... Average Loss for Epoch: 0.0008702666964381933\n",
      "Epoch 9......Step: 4/7....... Average Loss for Epoch: 0.0007935312460176647\n",
      "Epoch 9......Step: 5/7....... Average Loss for Epoch: 0.0007087765610776841\n",
      "Epoch 9......Step: 6/7....... Average Loss for Epoch: 0.0007492459553759545\n",
      "Epoch 9......Step: 7/7....... Average Loss for Epoch: 0.0007713858088079308\n",
      "Epoch 9/100 Done, Total Loss: 0.0007713858088079308\n",
      "Total Time Elapsed: 1.21875 seconds\n",
      "Epoch 10......Step: 1/7....... Average Loss for Epoch: 0.0005079311085864902\n",
      "Epoch 10......Step: 2/7....... Average Loss for Epoch: 0.0005932635976932943\n",
      "Epoch 10......Step: 3/7....... Average Loss for Epoch: 0.0005993935046717525\n",
      "Epoch 10......Step: 4/7....... Average Loss for Epoch: 0.0009106741636060178\n",
      "Epoch 10......Step: 5/7....... Average Loss for Epoch: 0.000910014531109482\n",
      "Epoch 10......Step: 6/7....... Average Loss for Epoch: 0.0008131390544197833\n",
      "Epoch 10......Step: 7/7....... Average Loss for Epoch: 0.0007670517037955246\n",
      "Epoch 10/100 Done, Total Loss: 0.0007670517037955246\n",
      "Total Time Elapsed: 1.09375 seconds\n",
      "Epoch 11......Step: 1/7....... Average Loss for Epoch: 0.0011227065697312355\n",
      "Epoch 11......Step: 2/7....... Average Loss for Epoch: 0.000829376105684787\n",
      "Epoch 11......Step: 3/7....... Average Loss for Epoch: 0.0006645036143405983\n",
      "Epoch 11......Step: 4/7....... Average Loss for Epoch: 0.0008042799236136489\n",
      "Epoch 11......Step: 5/7....... Average Loss for Epoch: 0.0007296844676602631\n",
      "Epoch 11......Step: 6/7....... Average Loss for Epoch: 0.0007187095422220106\n",
      "Epoch 11......Step: 7/7....... Average Loss for Epoch: 0.000712757177617667\n",
      "Epoch 11/100 Done, Total Loss: 0.000712757177617667\n",
      "Total Time Elapsed: 1.125 seconds\n",
      "Epoch 12......Step: 1/7....... Average Loss for Epoch: 0.00024701713118702173\n",
      "Epoch 12......Step: 2/7....... Average Loss for Epoch: 0.000699791475199163\n",
      "Epoch 12......Step: 3/7....... Average Loss for Epoch: 0.0007710727901818851\n",
      "Epoch 12......Step: 4/7....... Average Loss for Epoch: 0.0007140697125578299\n",
      "Epoch 12......Step: 5/7....... Average Loss for Epoch: 0.0006469433079473675\n",
      "Epoch 12......Step: 6/7....... Average Loss for Epoch: 0.0005839410975265006\n",
      "Epoch 12......Step: 7/7....... Average Loss for Epoch: 0.0005503328949479121\n",
      "Epoch 12/100 Done, Total Loss: 0.0005503328949479121\n",
      "Total Time Elapsed: 1.0 seconds\n",
      "Epoch 13......Step: 1/7....... Average Loss for Epoch: 0.001231420785188675\n",
      "Epoch 13......Step: 2/7....... Average Loss for Epoch: 0.0009490424126852304\n",
      "Epoch 13......Step: 3/7....... Average Loss for Epoch: 0.0007460619284150501\n",
      "Epoch 13......Step: 4/7....... Average Loss for Epoch: 0.0006802531061111949\n",
      "Epoch 13......Step: 5/7....... Average Loss for Epoch: 0.0006208942679222674\n",
      "Epoch 13......Step: 6/7....... Average Loss for Epoch: 0.0006475599511759356\n",
      "Epoch 13......Step: 7/7....... Average Loss for Epoch: 0.0006084105739968696\n",
      "Epoch 13/100 Done, Total Loss: 0.0006084105739968696\n",
      "Total Time Elapsed: 1.109375 seconds\n",
      "Epoch 14......Step: 1/7....... Average Loss for Epoch: 0.0003301549004390836\n",
      "Epoch 14......Step: 2/7....... Average Loss for Epoch: 0.0003537841548677534\n",
      "Epoch 14......Step: 3/7....... Average Loss for Epoch: 0.00042811860718453926\n",
      "Epoch 14......Step: 4/7....... Average Loss for Epoch: 0.0004525356343947351\n",
      "Epoch 14......Step: 5/7....... Average Loss for Epoch: 0.00045420202659443023\n",
      "Epoch 14......Step: 6/7....... Average Loss for Epoch: 0.00047041074139997363\n",
      "Epoch 14......Step: 7/7....... Average Loss for Epoch: 0.000572858245245048\n",
      "Epoch 14/100 Done, Total Loss: 0.000572858245245048\n",
      "Total Time Elapsed: 0.890625 seconds\n",
      "Epoch 15......Step: 1/7....... Average Loss for Epoch: 0.0005704765790142119\n",
      "Epoch 15......Step: 2/7....... Average Loss for Epoch: 0.0005146095354575664\n",
      "Epoch 15......Step: 3/7....... Average Loss for Epoch: 0.0006617376542029282\n",
      "Epoch 15......Step: 4/7....... Average Loss for Epoch: 0.0006728208973072469\n",
      "Epoch 15......Step: 5/7....... Average Loss for Epoch: 0.000667124125175178\n",
      "Epoch 15......Step: 6/7....... Average Loss for Epoch: 0.0006770582986064255\n",
      "Epoch 15......Step: 7/7....... Average Loss for Epoch: 0.0006178434040131313\n",
      "Epoch 15/100 Done, Total Loss: 0.0006178434040131313\n",
      "Total Time Elapsed: 0.671875 seconds\n",
      "Epoch 16......Step: 1/7....... Average Loss for Epoch: 0.00035257491981610656\n",
      "Epoch 16......Step: 2/7....... Average Loss for Epoch: 0.00024728450080147013\n",
      "Epoch 16......Step: 3/7....... Average Loss for Epoch: 0.0006224737492933249\n",
      "Epoch 16......Step: 4/7....... Average Loss for Epoch: 0.0006199467425176408\n",
      "Epoch 16......Step: 5/7....... Average Loss for Epoch: 0.0006450193439377471\n",
      "Epoch 16......Step: 6/7....... Average Loss for Epoch: 0.0006040733690800456\n",
      "Epoch 16......Step: 7/7....... Average Loss for Epoch: 0.0005617221987839523\n",
      "Epoch 16/100 Done, Total Loss: 0.0005617221987839523\n",
      "Total Time Elapsed: 0.828125 seconds\n",
      "Epoch 17......Step: 1/7....... Average Loss for Epoch: 0.0003700789238791913\n",
      "Epoch 17......Step: 2/7....... Average Loss for Epoch: 0.0007125466217985377\n",
      "Epoch 17......Step: 3/7....... Average Loss for Epoch: 0.0006659428957694521\n",
      "Epoch 17......Step: 4/7....... Average Loss for Epoch: 0.0005902789052925073\n",
      "Epoch 17......Step: 5/7....... Average Loss for Epoch: 0.0005398776964284479\n",
      "Epoch 17......Step: 6/7....... Average Loss for Epoch: 0.0005090170161565766\n",
      "Epoch 17......Step: 7/7....... Average Loss for Epoch: 0.0004792961449961045\n",
      "Epoch 17/100 Done, Total Loss: 0.0004792961449961045\n",
      "Total Time Elapsed: 1.046875 seconds\n",
      "Epoch 18......Step: 1/7....... Average Loss for Epoch: 0.00031034182757139206\n",
      "Epoch 18......Step: 2/7....... Average Loss for Epoch: 0.0003637364716269076\n",
      "Epoch 18......Step: 3/7....... Average Loss for Epoch: 0.00033058049545312923\n",
      "Epoch 18......Step: 4/7....... Average Loss for Epoch: 0.000561909211683087\n",
      "Epoch 18......Step: 5/7....... Average Loss for Epoch: 0.0005493061966262758\n",
      "Epoch 18......Step: 6/7....... Average Loss for Epoch: 0.0005952402910528084\n",
      "Epoch 18......Step: 7/7....... Average Loss for Epoch: 0.0005430939698791397\n",
      "Epoch 18/100 Done, Total Loss: 0.0005430939698791397\n",
      "Total Time Elapsed: 1.140625 seconds\n",
      "Epoch 19......Step: 1/7....... Average Loss for Epoch: 0.0007342835306189954\n",
      "Epoch 19......Step: 2/7....... Average Loss for Epoch: 0.0005407996795838699\n",
      "Epoch 19......Step: 3/7....... Average Loss for Epoch: 0.000462970221027111\n",
      "Epoch 19......Step: 4/7....... Average Loss for Epoch: 0.0005364435564843006\n",
      "Epoch 19......Step: 5/7....... Average Loss for Epoch: 0.0004922594758681953\n",
      "Epoch 19......Step: 6/7....... Average Loss for Epoch: 0.0004408664778262998\n",
      "Epoch 19......Step: 7/7....... Average Loss for Epoch: 0.0004198456382645028\n",
      "Epoch 19/100 Done, Total Loss: 0.0004198456382645028\n",
      "Total Time Elapsed: 0.9375 seconds\n",
      "Epoch 20......Step: 1/7....... Average Loss for Epoch: 0.0005032459739595652\n",
      "Epoch 20......Step: 2/7....... Average Loss for Epoch: 0.0003913453983841464\n",
      "Epoch 20......Step: 3/7....... Average Loss for Epoch: 0.0003950893102834622\n",
      "Epoch 20......Step: 4/7....... Average Loss for Epoch: 0.0005443718982860446\n",
      "Epoch 20......Step: 5/7....... Average Loss for Epoch: 0.0005202395259402692\n",
      "Epoch 20......Step: 6/7....... Average Loss for Epoch: 0.0005110958106039712\n",
      "Epoch 20......Step: 7/7....... Average Loss for Epoch: 0.0006284197443164885\n",
      "Epoch 20/100 Done, Total Loss: 0.0006284197443164885\n",
      "Total Time Elapsed: 1.140625 seconds\n",
      "Epoch 21......Step: 1/7....... Average Loss for Epoch: 0.00034997687907889485\n",
      "Epoch 21......Step: 2/7....... Average Loss for Epoch: 0.0006698212528135628\n",
      "Epoch 21......Step: 3/7....... Average Loss for Epoch: 0.0005468021554406732\n",
      "Epoch 21......Step: 4/7....... Average Loss for Epoch: 0.0005486374357133172\n",
      "Epoch 21......Step: 5/7....... Average Loss for Epoch: 0.0006492428190540522\n",
      "Epoch 21......Step: 6/7....... Average Loss for Epoch: 0.0006529728658885384\n",
      "Epoch 21......Step: 7/7....... Average Loss for Epoch: 0.0005938673670503444\n",
      "Epoch 21/100 Done, Total Loss: 0.0005938673670503444\n",
      "Total Time Elapsed: 1.03125 seconds\n",
      "Epoch 22......Step: 1/7....... Average Loss for Epoch: 0.001044461503624916\n",
      "Epoch 22......Step: 2/7....... Average Loss for Epoch: 0.000718652896466665\n",
      "Epoch 22......Step: 3/7....... Average Loss for Epoch: 0.0005848974493953089\n",
      "Epoch 22......Step: 4/7....... Average Loss for Epoch: 0.0005236300639808178\n",
      "Epoch 22......Step: 5/7....... Average Loss for Epoch: 0.0006306579802185297\n",
      "Epoch 22......Step: 6/7....... Average Loss for Epoch: 0.0006095970650979629\n",
      "Epoch 22......Step: 7/7....... Average Loss for Epoch: 0.0005585949069687299\n",
      "Epoch 22/100 Done, Total Loss: 0.0005585949069687299\n",
      "Total Time Elapsed: 1.109375 seconds\n",
      "Epoch 23......Step: 1/7....... Average Loss for Epoch: 0.00041970034362748265\n",
      "Epoch 23......Step: 2/7....... Average Loss for Epoch: 0.0003657785418909043\n",
      "Epoch 23......Step: 3/7....... Average Loss for Epoch: 0.0006516591529361904\n",
      "Epoch 23......Step: 4/7....... Average Loss for Epoch: 0.0006154653819976375\n",
      "Epoch 23......Step: 5/7....... Average Loss for Epoch: 0.0005664343247190118\n",
      "Epoch 23......Step: 6/7....... Average Loss for Epoch: 0.0005994962314919879\n",
      "Epoch 23......Step: 7/7....... Average Loss for Epoch: 0.0005617346448291625\n",
      "Epoch 23/100 Done, Total Loss: 0.0005617346448291625\n",
      "Total Time Elapsed: 1.15625 seconds\n",
      "Epoch 24......Step: 1/7....... Average Loss for Epoch: 0.0006135061266832054\n",
      "Epoch 24......Step: 2/7....... Average Loss for Epoch: 0.0005431344179669395\n",
      "Epoch 24......Step: 3/7....... Average Loss for Epoch: 0.00044602992905614275\n",
      "Epoch 24......Step: 4/7....... Average Loss for Epoch: 0.00042610742821125314\n",
      "Epoch 24......Step: 5/7....... Average Loss for Epoch: 0.0006963862513657659\n",
      "Epoch 24......Step: 6/7....... Average Loss for Epoch: 0.0006512244096181045\n",
      "Epoch 24......Step: 7/7....... Average Loss for Epoch: 0.0006193678543370749\n",
      "Epoch 24/100 Done, Total Loss: 0.0006193678543370749\n",
      "Total Time Elapsed: 1.015625 seconds\n",
      "Epoch 25......Step: 1/7....... Average Loss for Epoch: 0.0003623816301114857\n",
      "Epoch 25......Step: 2/7....... Average Loss for Epoch: 0.0007767692150082439\n",
      "Epoch 25......Step: 3/7....... Average Loss for Epoch: 0.0006158654772055646\n",
      "Epoch 25......Step: 4/7....... Average Loss for Epoch: 0.0007831241382518783\n",
      "Epoch 25......Step: 5/7....... Average Loss for Epoch: 0.0006751462118700146\n",
      "Epoch 25......Step: 6/7....... Average Loss for Epoch: 0.0006351360255697122\n",
      "Epoch 25......Step: 7/7....... Average Loss for Epoch: 0.0005792441058604579\n",
      "Epoch 25/100 Done, Total Loss: 0.0005792441058604579\n",
      "Total Time Elapsed: 1.09375 seconds\n",
      "Epoch 26......Step: 1/7....... Average Loss for Epoch: 0.00029406807152554393\n",
      "Epoch 26......Step: 2/7....... Average Loss for Epoch: 0.00035339842725079507\n",
      "Epoch 26......Step: 3/7....... Average Loss for Epoch: 0.00044145373976789415\n",
      "Epoch 26......Step: 4/7....... Average Loss for Epoch: 0.00046093218406895176\n",
      "Epoch 26......Step: 5/7....... Average Loss for Epoch: 0.0005319668620359152\n",
      "Epoch 26......Step: 6/7....... Average Loss for Epoch: 0.0004948049803109219\n",
      "Epoch 26......Step: 7/7....... Average Loss for Epoch: 0.0005859334903237011\n",
      "Epoch 26/100 Done, Total Loss: 0.0005859334903237011\n",
      "Total Time Elapsed: 1.0 seconds\n",
      "Epoch 27......Step: 1/7....... Average Loss for Epoch: 0.00034599524224177003\n",
      "Epoch 27......Step: 2/7....... Average Loss for Epoch: 0.00031860711169429123\n",
      "Epoch 27......Step: 3/7....... Average Loss for Epoch: 0.0002918734826380387\n",
      "Epoch 27......Step: 4/7....... Average Loss for Epoch: 0.000521489459060831\n",
      "Epoch 27......Step: 5/7....... Average Loss for Epoch: 0.0005745410773670301\n",
      "Epoch 27......Step: 6/7....... Average Loss for Epoch: 0.0005224801546622378\n",
      "Epoch 27......Step: 7/7....... Average Loss for Epoch: 0.0005319252813933417\n",
      "Epoch 27/100 Done, Total Loss: 0.0005319252813933417\n",
      "Total Time Elapsed: 1.03125 seconds\n",
      "Epoch 28......Step: 1/7....... Average Loss for Epoch: 0.00047005919623188674\n",
      "Epoch 28......Step: 2/7....... Average Loss for Epoch: 0.0003522710467223078\n",
      "Epoch 28......Step: 3/7....... Average Loss for Epoch: 0.0003515057226953407\n",
      "Epoch 28......Step: 4/7....... Average Loss for Epoch: 0.000453347951406613\n",
      "Epoch 28......Step: 5/7....... Average Loss for Epoch: 0.0005609996616840363\n",
      "Epoch 28......Step: 6/7....... Average Loss for Epoch: 0.0005220096209086478\n",
      "Epoch 28......Step: 7/7....... Average Loss for Epoch: 0.0005277167157536107\n",
      "Epoch 28/100 Done, Total Loss: 0.0005277167157536107\n",
      "Total Time Elapsed: 1.03125 seconds\n",
      "Epoch 29......Step: 1/7....... Average Loss for Epoch: 0.001020020223222673\n",
      "Epoch 29......Step: 2/7....... Average Loss for Epoch: 0.0006536288565257564\n",
      "Epoch 29......Step: 3/7....... Average Loss for Epoch: 0.000562059566921865\n",
      "Epoch 29......Step: 4/7....... Average Loss for Epoch: 0.0004849455217481591\n",
      "Epoch 29......Step: 5/7....... Average Loss for Epoch: 0.00047245759633369745\n",
      "Epoch 29......Step: 6/7....... Average Loss for Epoch: 0.0004392011809007575\n",
      "Epoch 29......Step: 7/7....... Average Loss for Epoch: 0.00043379611036341103\n",
      "Epoch 29/100 Done, Total Loss: 0.00043379611036341103\n",
      "Total Time Elapsed: 1.21875 seconds\n",
      "Epoch 30......Step: 1/7....... Average Loss for Epoch: 0.00026769418036565185\n",
      "Epoch 30......Step: 2/7....... Average Loss for Epoch: 0.0002513521249056794\n",
      "Epoch 30......Step: 3/7....... Average Loss for Epoch: 0.0002470903127687052\n",
      "Epoch 30......Step: 4/7....... Average Loss for Epoch: 0.0005921179508732166\n",
      "Epoch 30......Step: 5/7....... Average Loss for Epoch: 0.0005351723433705047\n",
      "Epoch 30......Step: 6/7....... Average Loss for Epoch: 0.0005104023560609979\n",
      "Epoch 30......Step: 7/7....... Average Loss for Epoch: 0.000489273904739613\n",
      "Epoch 30/100 Done, Total Loss: 0.000489273904739613\n",
      "Total Time Elapsed: 1.0 seconds\n",
      "Epoch 31......Step: 1/7....... Average Loss for Epoch: 0.0005467121955007315\n",
      "Epoch 31......Step: 2/7....... Average Loss for Epoch: 0.0004654635122278705\n",
      "Epoch 31......Step: 3/7....... Average Loss for Epoch: 0.0004462195502128452\n",
      "Epoch 31......Step: 4/7....... Average Loss for Epoch: 0.0006046515845810063\n",
      "Epoch 31......Step: 5/7....... Average Loss for Epoch: 0.000545315135968849\n",
      "Epoch 31......Step: 6/7....... Average Loss for Epoch: 0.0005040223816952979\n",
      "Epoch 31......Step: 7/7....... Average Loss for Epoch: 0.0005095565450444285\n",
      "Epoch 31/100 Done, Total Loss: 0.0005095565450444285\n",
      "Total Time Elapsed: 1.1875 seconds\n",
      "Epoch 32......Step: 1/7....... Average Loss for Epoch: 0.0004333371762186289\n",
      "Epoch 32......Step: 2/7....... Average Loss for Epoch: 0.0003283671903773211\n",
      "Epoch 32......Step: 3/7....... Average Loss for Epoch: 0.000365500440238975\n",
      "Epoch 32......Step: 4/7....... Average Loss for Epoch: 0.0003402330657991115\n",
      "Epoch 32......Step: 5/7....... Average Loss for Epoch: 0.00033615744614508004\n",
      "Epoch 32......Step: 6/7....... Average Loss for Epoch: 0.00038871497721023235\n",
      "Epoch 32......Step: 7/7....... Average Loss for Epoch: 0.0005003826123096847\n",
      "Epoch 32/100 Done, Total Loss: 0.0005003826123096847\n",
      "Total Time Elapsed: 1.078125 seconds\n",
      "Epoch 33......Step: 1/7....... Average Loss for Epoch: 0.0002896821533795446\n",
      "Epoch 33......Step: 2/7....... Average Loss for Epoch: 0.0005635944980895147\n",
      "Epoch 33......Step: 3/7....... Average Loss for Epoch: 0.0005265548922276745\n",
      "Epoch 33......Step: 4/7....... Average Loss for Epoch: 0.00046868900972185656\n",
      "Epoch 33......Step: 5/7....... Average Loss for Epoch: 0.0006187152059283108\n",
      "Epoch 33......Step: 6/7....... Average Loss for Epoch: 0.0005963979492662475\n",
      "Epoch 33......Step: 7/7....... Average Loss for Epoch: 0.0005788739778966244\n",
      "Epoch 33/100 Done, Total Loss: 0.0005788739778966244\n",
      "Total Time Elapsed: 1.0 seconds\n",
      "Epoch 34......Step: 1/7....... Average Loss for Epoch: 0.00035111786564812064\n",
      "Epoch 34......Step: 2/7....... Average Loss for Epoch: 0.0004848467360716313\n",
      "Epoch 34......Step: 3/7....... Average Loss for Epoch: 0.0005840417773773273\n",
      "Epoch 34......Step: 4/7....... Average Loss for Epoch: 0.0005127068943693303\n",
      "Epoch 34......Step: 5/7....... Average Loss for Epoch: 0.0005035646085161716\n",
      "Epoch 34......Step: 6/7....... Average Loss for Epoch: 0.00047118669317569584\n",
      "Epoch 34......Step: 7/7....... Average Loss for Epoch: 0.0005755408409251166\n",
      "Epoch 34/100 Done, Total Loss: 0.0005755408409251166\n",
      "Total Time Elapsed: 1.3125 seconds\n",
      "Epoch 35......Step: 1/7....... Average Loss for Epoch: 0.00025544341770000756\n",
      "Epoch 35......Step: 2/7....... Average Loss for Epoch: 0.00031789384956937283\n",
      "Epoch 35......Step: 3/7....... Average Loss for Epoch: 0.00041719230163532\n",
      "Epoch 35......Step: 4/7....... Average Loss for Epoch: 0.0004425073057063855\n",
      "Epoch 35......Step: 5/7....... Average Loss for Epoch: 0.0004433441150467843\n",
      "Epoch 35......Step: 6/7....... Average Loss for Epoch: 0.00044095105355760705\n",
      "Epoch 35......Step: 7/7....... Average Loss for Epoch: 0.0004154205962549895\n",
      "Epoch 35/100 Done, Total Loss: 0.0004154205962549895\n",
      "Total Time Elapsed: 1.109375 seconds\n",
      "Epoch 36......Step: 1/7....... Average Loss for Epoch: 0.0014167199842631817\n",
      "Epoch 36......Step: 2/7....... Average Loss for Epoch: 0.0012384004076011479\n",
      "Epoch 36......Step: 3/7....... Average Loss for Epoch: 0.0009148678121467432\n",
      "Epoch 36......Step: 4/7....... Average Loss for Epoch: 0.000753110958612524\n",
      "Epoch 36......Step: 5/7....... Average Loss for Epoch: 0.0007471261196769774\n",
      "Epoch 36......Step: 6/7....... Average Loss for Epoch: 0.0006607027438197596\n",
      "Epoch 36......Step: 7/7....... Average Loss for Epoch: 0.000607709473115392\n",
      "Epoch 36/100 Done, Total Loss: 0.000607709473115392\n",
      "Total Time Elapsed: 1.09375 seconds\n",
      "Epoch 37......Step: 1/7....... Average Loss for Epoch: 0.000543942442163825\n",
      "Epoch 37......Step: 2/7....... Average Loss for Epoch: 0.00041936316119972616\n",
      "Epoch 37......Step: 3/7....... Average Loss for Epoch: 0.0003936045589701583\n",
      "Epoch 37......Step: 4/7....... Average Loss for Epoch: 0.00038232403312576935\n",
      "Epoch 37......Step: 5/7....... Average Loss for Epoch: 0.0004373981093522161\n",
      "Epoch 37......Step: 6/7....... Average Loss for Epoch: 0.00041535592754371464\n",
      "Epoch 37......Step: 7/7....... Average Loss for Epoch: 0.0005207657398256872\n",
      "Epoch 37/100 Done, Total Loss: 0.0005207657398256872\n",
      "Total Time Elapsed: 1.09375 seconds\n",
      "Epoch 38......Step: 1/7....... Average Loss for Epoch: 0.00018889972125180066\n",
      "Epoch 38......Step: 2/7....... Average Loss for Epoch: 0.0003998250322183594\n",
      "Epoch 38......Step: 3/7....... Average Loss for Epoch: 0.0005132633862861743\n",
      "Epoch 38......Step: 4/7....... Average Loss for Epoch: 0.0004677951437770389\n",
      "Epoch 38......Step: 5/7....... Average Loss for Epoch: 0.0005836559401359409\n",
      "Epoch 38......Step: 6/7....... Average Loss for Epoch: 0.0005244252170086838\n",
      "Epoch 38......Step: 7/7....... Average Loss for Epoch: 0.0005255227089427146\n",
      "Epoch 38/100 Done, Total Loss: 0.0005255227089427146\n",
      "Total Time Elapsed: 1.171875 seconds\n",
      "Epoch 39......Step: 1/7....... Average Loss for Epoch: 0.00025949679547920823\n",
      "Epoch 39......Step: 2/7....... Average Loss for Epoch: 0.00035499315708875656\n",
      "Epoch 39......Step: 3/7....... Average Loss for Epoch: 0.00032322660748225945\n",
      "Epoch 39......Step: 4/7....... Average Loss for Epoch: 0.000471229046524968\n",
      "Epoch 39......Step: 5/7....... Average Loss for Epoch: 0.00043790877680294216\n",
      "Epoch 39......Step: 6/7....... Average Loss for Epoch: 0.00045581862893110764\n",
      "Epoch 39......Step: 7/7....... Average Loss for Epoch: 0.00041821232714158086\n",
      "Epoch 39/100 Done, Total Loss: 0.00041821232714158086\n",
      "Total Time Elapsed: 1.015625 seconds\n",
      "Epoch 40......Step: 1/7....... Average Loss for Epoch: 0.00029636608087457716\n",
      "Epoch 40......Step: 2/7....... Average Loss for Epoch: 0.0002799832873279229\n",
      "Epoch 40......Step: 3/7....... Average Loss for Epoch: 0.0003362876983980338\n",
      "Epoch 40......Step: 4/7....... Average Loss for Epoch: 0.0005386997363530099\n",
      "Epoch 40......Step: 5/7....... Average Loss for Epoch: 0.0005228957918006927\n",
      "Epoch 40......Step: 6/7....... Average Loss for Epoch: 0.0005442608623222137\n",
      "Epoch 40......Step: 7/7....... Average Loss for Epoch: 0.0004964967374689877\n",
      "Epoch 40/100 Done, Total Loss: 0.0004964967374689877\n",
      "Total Time Elapsed: 1.109375 seconds\n",
      "Epoch 41......Step: 1/7....... Average Loss for Epoch: 0.00062079745111987\n",
      "Epoch 41......Step: 2/7....... Average Loss for Epoch: 0.0009799279796425253\n",
      "Epoch 41......Step: 3/7....... Average Loss for Epoch: 0.0008062096991731474\n",
      "Epoch 41......Step: 4/7....... Average Loss for Epoch: 0.0006890715885674581\n",
      "Epoch 41......Step: 5/7....... Average Loss for Epoch: 0.0006218762020580471\n",
      "Epoch 41......Step: 6/7....... Average Loss for Epoch: 0.0005929963323675717\n",
      "Epoch 41......Step: 7/7....... Average Loss for Epoch: 0.0005338581208239443\n",
      "Epoch 41/100 Done, Total Loss: 0.0005338581208239443\n",
      "Total Time Elapsed: 1.078125 seconds\n",
      "Epoch 42......Step: 1/7....... Average Loss for Epoch: 0.0006979617173783481\n",
      "Epoch 42......Step: 2/7....... Average Loss for Epoch: 0.0009359869000036269\n",
      "Epoch 42......Step: 3/7....... Average Loss for Epoch: 0.0007739954647452881\n",
      "Epoch 42......Step: 4/7....... Average Loss for Epoch: 0.0006767438244423829\n",
      "Epoch 42......Step: 5/7....... Average Loss for Epoch: 0.0005918387032579631\n",
      "Epoch 42......Step: 6/7....... Average Loss for Epoch: 0.0005910340454041337\n",
      "Epoch 42......Step: 7/7....... Average Loss for Epoch: 0.0005272593532156732\n",
      "Epoch 42/100 Done, Total Loss: 0.0005272593532156732\n",
      "Total Time Elapsed: 1.109375 seconds\n",
      "Epoch 43......Step: 1/7....... Average Loss for Epoch: 0.00048373505705967546\n",
      "Epoch 43......Step: 2/7....... Average Loss for Epoch: 0.0003585527665563859\n",
      "Epoch 43......Step: 3/7....... Average Loss for Epoch: 0.00033308128574086976\n",
      "Epoch 43......Step: 4/7....... Average Loss for Epoch: 0.00034407790008117445\n",
      "Epoch 43......Step: 5/7....... Average Loss for Epoch: 0.00040550079720560463\n",
      "Epoch 43......Step: 6/7....... Average Loss for Epoch: 0.00039863698232996586\n",
      "Epoch 43......Step: 7/7....... Average Loss for Epoch: 0.000383919248374046\n",
      "Epoch 43/100 Done, Total Loss: 0.000383919248374046\n",
      "Total Time Elapsed: 1.09375 seconds\n",
      "Epoch 44......Step: 1/7....... Average Loss for Epoch: 0.0002466734731569886\n",
      "Epoch 44......Step: 2/7....... Average Loss for Epoch: 0.00026372999127488583\n",
      "Epoch 44......Step: 3/7....... Average Loss for Epoch: 0.0004762751729382823\n",
      "Epoch 44......Step: 4/7....... Average Loss for Epoch: 0.00047380367323057726\n",
      "Epoch 44......Step: 5/7....... Average Loss for Epoch: 0.000440391490701586\n",
      "Epoch 44......Step: 6/7....... Average Loss for Epoch: 0.0004253060615155846\n",
      "Epoch 44......Step: 7/7....... Average Loss for Epoch: 0.0005288607623827245\n",
      "Epoch 44/100 Done, Total Loss: 0.0005288607623827245\n",
      "Total Time Elapsed: 1.09375 seconds\n",
      "Epoch 45......Step: 1/7....... Average Loss for Epoch: 0.00027935116668231785\n",
      "Epoch 45......Step: 2/7....... Average Loss for Epoch: 0.00032202810689341277\n",
      "Epoch 45......Step: 3/7....... Average Loss for Epoch: 0.0003066673040545235\n",
      "Epoch 45......Step: 4/7....... Average Loss for Epoch: 0.00035796101292362437\n",
      "Epoch 45......Step: 5/7....... Average Loss for Epoch: 0.0004835660278331488\n",
      "Epoch 45......Step: 6/7....... Average Loss for Epoch: 0.0004501191870076582\n",
      "Epoch 45......Step: 7/7....... Average Loss for Epoch: 0.0004272481476488922\n",
      "Epoch 45/100 Done, Total Loss: 0.0004272481476488922\n",
      "Total Time Elapsed: 1.171875 seconds\n",
      "Epoch 46......Step: 1/7....... Average Loss for Epoch: 0.00032611697679385543\n",
      "Epoch 46......Step: 2/7....... Average Loss for Epoch: 0.000310294606606476\n",
      "Epoch 46......Step: 3/7....... Average Loss for Epoch: 0.00028486935480032116\n",
      "Epoch 46......Step: 4/7....... Average Loss for Epoch: 0.00030301263541332446\n",
      "Epoch 46......Step: 5/7....... Average Loss for Epoch: 0.00033063683367799966\n",
      "Epoch 46......Step: 6/7....... Average Loss for Epoch: 0.0003210535966597187\n",
      "Epoch 46......Step: 7/7....... Average Loss for Epoch: 0.0004793093934754974\n",
      "Epoch 46/100 Done, Total Loss: 0.0004793093934754974\n",
      "Total Time Elapsed: 1.1875 seconds\n",
      "Epoch 47......Step: 1/7....... Average Loss for Epoch: 0.001234945491887629\n",
      "Epoch 47......Step: 2/7....... Average Loss for Epoch: 0.0009387957979924977\n",
      "Epoch 47......Step: 3/7....... Average Loss for Epoch: 0.0007614886077741782\n",
      "Epoch 47......Step: 4/7....... Average Loss for Epoch: 0.0006254959662328474\n",
      "Epoch 47......Step: 5/7....... Average Loss for Epoch: 0.0005702883237972856\n",
      "Epoch 47......Step: 6/7....... Average Loss for Epoch: 0.0005382298453090092\n",
      "Epoch 47......Step: 7/7....... Average Loss for Epoch: 0.0004923736518581531\n",
      "Epoch 47/100 Done, Total Loss: 0.0004923736518581531\n",
      "Total Time Elapsed: 1.03125 seconds\n",
      "Epoch 48......Step: 1/7....... Average Loss for Epoch: 0.0006411286885850132\n",
      "Epoch 48......Step: 2/7....... Average Loss for Epoch: 0.0008912536723073572\n",
      "Epoch 48......Step: 3/7....... Average Loss for Epoch: 0.0006881456647533923\n",
      "Epoch 48......Step: 4/7....... Average Loss for Epoch: 0.0006245577897061594\n",
      "Epoch 48......Step: 5/7....... Average Loss for Epoch: 0.0005906422215048224\n",
      "Epoch 48......Step: 6/7....... Average Loss for Epoch: 0.000553624156358031\n",
      "Epoch 48......Step: 7/7....... Average Loss for Epoch: 0.0004996117370735322\n",
      "Epoch 48/100 Done, Total Loss: 0.0004996117370735322\n",
      "Total Time Elapsed: 1.28125 seconds\n",
      "Epoch 49......Step: 1/7....... Average Loss for Epoch: 0.0005515188095159829\n",
      "Epoch 49......Step: 2/7....... Average Loss for Epoch: 0.0006324634596239775\n",
      "Epoch 49......Step: 3/7....... Average Loss for Epoch: 0.0008636344961511592\n",
      "Epoch 49......Step: 4/7....... Average Loss for Epoch: 0.0007020387602096889\n",
      "Epoch 49......Step: 5/7....... Average Loss for Epoch: 0.0006144659331766888\n",
      "Epoch 49......Step: 6/7....... Average Loss for Epoch: 0.0005469525058288127\n",
      "Epoch 49......Step: 7/7....... Average Loss for Epoch: 0.000516943824810109\n",
      "Epoch 49/100 Done, Total Loss: 0.000516943824810109\n",
      "Total Time Elapsed: 1.203125 seconds\n",
      "Epoch 50......Step: 1/7....... Average Loss for Epoch: 0.00037668447475880384\n",
      "Epoch 50......Step: 2/7....... Average Loss for Epoch: 0.00035149203904438764\n",
      "Epoch 50......Step: 3/7....... Average Loss for Epoch: 0.00039273947671366233\n",
      "Epoch 50......Step: 4/7....... Average Loss for Epoch: 0.0003717077925102785\n",
      "Epoch 50......Step: 5/7....... Average Loss for Epoch: 0.0005260822712443769\n",
      "Epoch 50......Step: 6/7....... Average Loss for Epoch: 0.0005590737758514782\n",
      "Epoch 50......Step: 7/7....... Average Loss for Epoch: 0.0005285053297744266\n",
      "Epoch 50/100 Done, Total Loss: 0.0005285053297744266\n",
      "Total Time Elapsed: 1.28125 seconds\n",
      "Epoch 51......Step: 1/7....... Average Loss for Epoch: 0.0015530565287917852\n",
      "Epoch 51......Step: 2/7....... Average Loss for Epoch: 0.0009146564989350736\n",
      "Epoch 51......Step: 3/7....... Average Loss for Epoch: 0.0007113980342789242\n",
      "Epoch 51......Step: 4/7....... Average Loss for Epoch: 0.0005997138723614626\n",
      "Epoch 51......Step: 5/7....... Average Loss for Epoch: 0.0005593876936472953\n",
      "Epoch 51......Step: 6/7....... Average Loss for Epoch: 0.0005406950270601859\n",
      "Epoch 51......Step: 7/7....... Average Loss for Epoch: 0.0005076491423616451\n",
      "Epoch 51/100 Done, Total Loss: 0.0005076491423616451\n",
      "Total Time Elapsed: 1.21875 seconds\n",
      "Epoch 52......Step: 1/7....... Average Loss for Epoch: 0.00017665304767433554\n",
      "Epoch 52......Step: 2/7....... Average Loss for Epoch: 0.0002256098305224441\n",
      "Epoch 52......Step: 3/7....... Average Loss for Epoch: 0.0003858563092459614\n",
      "Epoch 52......Step: 4/7....... Average Loss for Epoch: 0.0005815131989947986\n",
      "Epoch 52......Step: 5/7....... Average Loss for Epoch: 0.0005165144189959392\n",
      "Epoch 52......Step: 6/7....... Average Loss for Epoch: 0.0005058357758874384\n",
      "Epoch 52......Step: 7/7....... Average Loss for Epoch: 0.0004694138790780146\n",
      "Epoch 52/100 Done, Total Loss: 0.0004694138790780146\n",
      "Total Time Elapsed: 1.0 seconds\n",
      "Epoch 53......Step: 1/7....... Average Loss for Epoch: 0.0002685403451323509\n",
      "Epoch 53......Step: 2/7....... Average Loss for Epoch: 0.0006746702129021287\n",
      "Epoch 53......Step: 3/7....... Average Loss for Epoch: 0.0005389579746406525\n",
      "Epoch 53......Step: 4/7....... Average Loss for Epoch: 0.000509035678987857\n",
      "Epoch 53......Step: 5/7....... Average Loss for Epoch: 0.0005675249209161848\n",
      "Epoch 53......Step: 6/7....... Average Loss for Epoch: 0.0005130970942749021\n",
      "Epoch 53......Step: 7/7....... Average Loss for Epoch: 0.00046463960773378076\n",
      "Epoch 53/100 Done, Total Loss: 0.00046463960773378076\n",
      "Total Time Elapsed: 1.078125 seconds\n",
      "Epoch 54......Step: 1/7....... Average Loss for Epoch: 0.00040465607889927924\n",
      "Epoch 54......Step: 2/7....... Average Loss for Epoch: 0.0005797854246338829\n",
      "Epoch 54......Step: 3/7....... Average Loss for Epoch: 0.0005362525213665018\n",
      "Epoch 54......Step: 4/7....... Average Loss for Epoch: 0.0004851889025303535\n",
      "Epoch 54......Step: 5/7....... Average Loss for Epoch: 0.0004655596741940826\n",
      "Epoch 54......Step: 6/7....... Average Loss for Epoch: 0.0004319362245344867\n",
      "Epoch 54......Step: 7/7....... Average Loss for Epoch: 0.00047522982017004063\n",
      "Epoch 54/100 Done, Total Loss: 0.00047522982017004063\n",
      "Total Time Elapsed: 1.15625 seconds\n",
      "Epoch 55......Step: 1/7....... Average Loss for Epoch: 0.00040917209116742015\n",
      "Epoch 55......Step: 2/7....... Average Loss for Epoch: 0.0003581629862310365\n",
      "Epoch 55......Step: 3/7....... Average Loss for Epoch: 0.0003507568617351353\n",
      "Epoch 55......Step: 4/7....... Average Loss for Epoch: 0.0006148597894934937\n",
      "Epoch 55......Step: 5/7....... Average Loss for Epoch: 0.0005406291515100747\n",
      "Epoch 55......Step: 6/7....... Average Loss for Epoch: 0.0005403030421196794\n",
      "Epoch 55......Step: 7/7....... Average Loss for Epoch: 0.0005164882292904492\n",
      "Epoch 55/100 Done, Total Loss: 0.0005164882292904492\n",
      "Total Time Elapsed: 1.09375 seconds\n",
      "Epoch 56......Step: 1/7....... Average Loss for Epoch: 0.000244392198510468\n",
      "Epoch 56......Step: 2/7....... Average Loss for Epoch: 0.00026297548902221024\n",
      "Epoch 56......Step: 3/7....... Average Loss for Epoch: 0.0002556467419102167\n",
      "Epoch 56......Step: 4/7....... Average Loss for Epoch: 0.00039052946885931306\n",
      "Epoch 56......Step: 5/7....... Average Loss for Epoch: 0.0005400779511546717\n",
      "Epoch 56......Step: 6/7....... Average Loss for Epoch: 0.0005186449682999713\n",
      "Epoch 56......Step: 7/7....... Average Loss for Epoch: 0.0005075159237354196\n",
      "Epoch 56/100 Done, Total Loss: 0.0005075159237354196\n",
      "Total Time Elapsed: 1.203125 seconds\n",
      "Epoch 57......Step: 1/7....... Average Loss for Epoch: 0.0005489827017299831\n",
      "Epoch 57......Step: 2/7....... Average Loss for Epoch: 0.0005780927313026041\n",
      "Epoch 57......Step: 3/7....... Average Loss for Epoch: 0.0005601639277301729\n",
      "Epoch 57......Step: 4/7....... Average Loss for Epoch: 0.0004769995757669676\n",
      "Epoch 57......Step: 5/7....... Average Loss for Epoch: 0.000528093651519157\n",
      "Epoch 57......Step: 6/7....... Average Loss for Epoch: 0.0005277431264403276\n",
      "Epoch 57......Step: 7/7....... Average Loss for Epoch: 0.0005637574712246922\n",
      "Epoch 57/100 Done, Total Loss: 0.0005637574712246922\n",
      "Total Time Elapsed: 1.109375 seconds\n",
      "Epoch 58......Step: 1/7....... Average Loss for Epoch: 0.0004750196821987629\n",
      "Epoch 58......Step: 2/7....... Average Loss for Epoch: 0.0005399927031248808\n",
      "Epoch 58......Step: 3/7....... Average Loss for Epoch: 0.0004201351257506758\n",
      "Epoch 58......Step: 4/7....... Average Loss for Epoch: 0.0004609110255842097\n",
      "Epoch 58......Step: 5/7....... Average Loss for Epoch: 0.0004709367698524147\n",
      "Epoch 58......Step: 6/7....... Average Loss for Epoch: 0.00042285182522997883\n",
      "Epoch 58......Step: 7/7....... Average Loss for Epoch: 0.00043098109017591923\n",
      "Epoch 58/100 Done, Total Loss: 0.00043098109017591923\n",
      "Total Time Elapsed: 1.140625 seconds\n",
      "Epoch 59......Step: 1/7....... Average Loss for Epoch: 0.00040888978401198983\n",
      "Epoch 59......Step: 2/7....... Average Loss for Epoch: 0.0005484258872456849\n",
      "Epoch 59......Step: 3/7....... Average Loss for Epoch: 0.00047221744898706675\n",
      "Epoch 59......Step: 4/7....... Average Loss for Epoch: 0.00045219621097203344\n",
      "Epoch 59......Step: 5/7....... Average Loss for Epoch: 0.0004021037311758846\n",
      "Epoch 59......Step: 6/7....... Average Loss for Epoch: 0.0004275872925063595\n",
      "Epoch 59......Step: 7/7....... Average Loss for Epoch: 0.0005082418418688965\n",
      "Epoch 59/100 Done, Total Loss: 0.0005082418418688965\n",
      "Total Time Elapsed: 1.09375 seconds\n",
      "Epoch 60......Step: 1/7....... Average Loss for Epoch: 0.00044696760596707463\n",
      "Epoch 60......Step: 2/7....... Average Loss for Epoch: 0.0007444458024110645\n",
      "Epoch 60......Step: 3/7....... Average Loss for Epoch: 0.0005834390661523988\n",
      "Epoch 60......Step: 4/7....... Average Loss for Epoch: 0.0005179795625736006\n",
      "Epoch 60......Step: 5/7....... Average Loss for Epoch: 0.0004995678027626127\n",
      "Epoch 60......Step: 6/7....... Average Loss for Epoch: 0.00045737285593835014\n",
      "Epoch 60......Step: 7/7....... Average Loss for Epoch: 0.0004357729672587344\n",
      "Epoch 60/100 Done, Total Loss: 0.0004357729672587344\n",
      "Total Time Elapsed: 1.203125 seconds\n",
      "Epoch 61......Step: 1/7....... Average Loss for Epoch: 0.00022185441048350185\n",
      "Epoch 61......Step: 2/7....... Average Loss for Epoch: 0.0002776498076855205\n",
      "Epoch 61......Step: 3/7....... Average Loss for Epoch: 0.000310838576600266\n",
      "Epoch 61......Step: 4/7....... Average Loss for Epoch: 0.0005242057995928917\n",
      "Epoch 61......Step: 5/7....... Average Loss for Epoch: 0.0005474402249092236\n",
      "Epoch 61......Step: 6/7....... Average Loss for Epoch: 0.0005131094294483773\n",
      "Epoch 61......Step: 7/7....... Average Loss for Epoch: 0.0004646246546014611\n",
      "Epoch 61/100 Done, Total Loss: 0.0004646246546014611\n",
      "Total Time Elapsed: 1.125 seconds\n",
      "Epoch 62......Step: 1/7....... Average Loss for Epoch: 0.00023147686442825943\n",
      "Epoch 62......Step: 2/7....... Average Loss for Epoch: 0.0006452899033320136\n",
      "Epoch 62......Step: 3/7....... Average Loss for Epoch: 0.0005515490047400817\n",
      "Epoch 62......Step: 4/7....... Average Loss for Epoch: 0.0005474075624078978\n",
      "Epoch 62......Step: 5/7....... Average Loss for Epoch: 0.0004882534994976595\n",
      "Epoch 62......Step: 6/7....... Average Loss for Epoch: 0.00044448715198086575\n",
      "Epoch 62......Step: 7/7....... Average Loss for Epoch: 0.0004863411200598681\n",
      "Epoch 62/100 Done, Total Loss: 0.0004863411200598681\n",
      "Total Time Elapsed: 1.125 seconds\n",
      "Epoch 63......Step: 1/7....... Average Loss for Epoch: 0.0010693359654396772\n",
      "Epoch 63......Step: 2/7....... Average Loss for Epoch: 0.0006708523142151535\n",
      "Epoch 63......Step: 3/7....... Average Loss for Epoch: 0.000522082492049473\n",
      "Epoch 63......Step: 4/7....... Average Loss for Epoch: 0.0004324702422309201\n",
      "Epoch 63......Step: 5/7....... Average Loss for Epoch: 0.00040158005722332744\n",
      "Epoch 63......Step: 6/7....... Average Loss for Epoch: 0.0003733951161848381\n",
      "Epoch 63......Step: 7/7....... Average Loss for Epoch: 0.0004256238420826516\n",
      "Epoch 63/100 Done, Total Loss: 0.0004256238420826516\n",
      "Total Time Elapsed: 1.21875 seconds\n",
      "Epoch 64......Step: 1/7....... Average Loss for Epoch: 0.0003999352047685534\n",
      "Epoch 64......Step: 2/7....... Average Loss for Epoch: 0.000280415486486163\n",
      "Epoch 64......Step: 3/7....... Average Loss for Epoch: 0.0005331939852718884\n",
      "Epoch 64......Step: 4/7....... Average Loss for Epoch: 0.00046086918155197054\n",
      "Epoch 64......Step: 5/7....... Average Loss for Epoch: 0.0004379970603622496\n",
      "Epoch 64......Step: 6/7....... Average Loss for Epoch: 0.00040692873396134627\n",
      "Epoch 64......Step: 7/7....... Average Loss for Epoch: 0.0004724755958055279\n",
      "Epoch 64/100 Done, Total Loss: 0.0004724755958055279\n",
      "Total Time Elapsed: 1.015625 seconds\n",
      "Epoch 65......Step: 1/7....... Average Loss for Epoch: 0.000285356305539608\n",
      "Epoch 65......Step: 2/7....... Average Loss for Epoch: 0.0003978982276748866\n",
      "Epoch 65......Step: 3/7....... Average Loss for Epoch: 0.00039316483889706433\n",
      "Epoch 65......Step: 4/7....... Average Loss for Epoch: 0.0003998061001766473\n",
      "Epoch 65......Step: 5/7....... Average Loss for Epoch: 0.0003682467708131298\n",
      "Epoch 65......Step: 6/7....... Average Loss for Epoch: 0.00033134862799973536\n",
      "Epoch 65......Step: 7/7....... Average Loss for Epoch: 0.0003464628659587886\n",
      "Epoch 65/100 Done, Total Loss: 0.0003464628659587886\n",
      "Total Time Elapsed: 1.203125 seconds\n",
      "Epoch 66......Step: 1/7....... Average Loss for Epoch: 0.00017440904048271477\n",
      "Epoch 66......Step: 2/7....... Average Loss for Epoch: 0.0004284495807951316\n",
      "Epoch 66......Step: 3/7....... Average Loss for Epoch: 0.000699148232039685\n",
      "Epoch 66......Step: 4/7....... Average Loss for Epoch: 0.0005929630788159557\n",
      "Epoch 66......Step: 5/7....... Average Loss for Epoch: 0.0005111942038638518\n",
      "Epoch 66......Step: 6/7....... Average Loss for Epoch: 0.0004849818966855916\n",
      "Epoch 66......Step: 7/7....... Average Loss for Epoch: 0.0004581956288477938\n",
      "Epoch 66/100 Done, Total Loss: 0.0004581956288477938\n",
      "Total Time Elapsed: 1.109375 seconds\n",
      "Epoch 67......Step: 1/7....... Average Loss for Epoch: 0.00032210408244282007\n",
      "Epoch 67......Step: 2/7....... Average Loss for Epoch: 0.00047373538836836815\n",
      "Epoch 67......Step: 3/7....... Average Loss for Epoch: 0.0005388512702969214\n",
      "Epoch 67......Step: 4/7....... Average Loss for Epoch: 0.000438488474173937\n",
      "Epoch 67......Step: 5/7....... Average Loss for Epoch: 0.0003950149373849854\n",
      "Epoch 67......Step: 6/7....... Average Loss for Epoch: 0.0003777348004708377\n",
      "Epoch 67......Step: 7/7....... Average Loss for Epoch: 0.0003520977812253737\n",
      "Epoch 67/100 Done, Total Loss: 0.0003520977812253737\n",
      "Total Time Elapsed: 1.078125 seconds\n",
      "Epoch 68......Step: 1/7....... Average Loss for Epoch: 0.0002196238492615521\n",
      "Epoch 68......Step: 2/7....... Average Loss for Epoch: 0.00034694699570536613\n",
      "Epoch 68......Step: 3/7....... Average Loss for Epoch: 0.00032985689661776024\n",
      "Epoch 68......Step: 4/7....... Average Loss for Epoch: 0.00041112110193353146\n",
      "Epoch 68......Step: 5/7....... Average Loss for Epoch: 0.0003779423306696117\n",
      "Epoch 68......Step: 6/7....... Average Loss for Epoch: 0.00037118774101448554\n",
      "Epoch 68......Step: 7/7....... Average Loss for Epoch: 0.00035131553054920265\n",
      "Epoch 68/100 Done, Total Loss: 0.00035131553054920265\n",
      "Total Time Elapsed: 1.078125 seconds\n",
      "Epoch 69......Step: 1/7....... Average Loss for Epoch: 0.0002722496574278921\n",
      "Epoch 69......Step: 2/7....... Average Loss for Epoch: 0.0002500601840438321\n",
      "Epoch 69......Step: 3/7....... Average Loss for Epoch: 0.0004147751509056737\n",
      "Epoch 69......Step: 4/7....... Average Loss for Epoch: 0.00042821760871447623\n",
      "Epoch 69......Step: 5/7....... Average Loss for Epoch: 0.0005530107067897916\n",
      "Epoch 69......Step: 6/7....... Average Loss for Epoch: 0.0005005008667164171\n",
      "Epoch 69......Step: 7/7....... Average Loss for Epoch: 0.00046676523717386384\n",
      "Epoch 69/100 Done, Total Loss: 0.00046676523717386384\n",
      "Total Time Elapsed: 1.09375 seconds\n",
      "Epoch 70......Step: 1/7....... Average Loss for Epoch: 0.00019657047232612967\n",
      "Epoch 70......Step: 2/7....... Average Loss for Epoch: 0.0007065600657369941\n",
      "Epoch 70......Step: 3/7....... Average Loss for Epoch: 0.0005757204780820757\n",
      "Epoch 70......Step: 4/7....... Average Loss for Epoch: 0.00048176481504924595\n",
      "Epoch 70......Step: 5/7....... Average Loss for Epoch: 0.000520098814740777\n",
      "Epoch 70......Step: 6/7....... Average Loss for Epoch: 0.000484606910807391\n",
      "Epoch 70......Step: 7/7....... Average Loss for Epoch: 0.00045421194434831183\n",
      "Epoch 70/100 Done, Total Loss: 0.00045421194434831183\n",
      "Total Time Elapsed: 1.140625 seconds\n",
      "Epoch 71......Step: 1/7....... Average Loss for Epoch: 0.00015519963926635683\n",
      "Epoch 71......Step: 2/7....... Average Loss for Epoch: 0.0002086371387122199\n",
      "Epoch 71......Step: 3/7....... Average Loss for Epoch: 0.00023111021922280392\n",
      "Epoch 71......Step: 4/7....... Average Loss for Epoch: 0.00023779700859449804\n",
      "Epoch 71......Step: 5/7....... Average Loss for Epoch: 0.000316123734228313\n",
      "Epoch 71......Step: 6/7....... Average Loss for Epoch: 0.0003103603133543705\n",
      "Epoch 71......Step: 7/7....... Average Loss for Epoch: 0.0004026541012405817\n",
      "Epoch 71/100 Done, Total Loss: 0.0004026541012405817\n",
      "Total Time Elapsed: 1.03125 seconds\n",
      "Epoch 72......Step: 1/7....... Average Loss for Epoch: 0.00044320939923636615\n",
      "Epoch 72......Step: 2/7....... Average Loss for Epoch: 0.0008496952796122059\n",
      "Epoch 72......Step: 3/7....... Average Loss for Epoch: 0.0009499956601454566\n",
      "Epoch 72......Step: 4/7....... Average Loss for Epoch: 0.0007906674654805101\n",
      "Epoch 72......Step: 5/7....... Average Loss for Epoch: 0.0007707590761128813\n",
      "Epoch 72......Step: 6/7....... Average Loss for Epoch: 0.0007004859653534368\n",
      "Epoch 72......Step: 7/7....... Average Loss for Epoch: 0.0006347093149088323\n",
      "Epoch 72/100 Done, Total Loss: 0.0006347093149088323\n",
      "Total Time Elapsed: 1.203125 seconds\n",
      "Epoch 73......Step: 1/7....... Average Loss for Epoch: 0.0003211653383914381\n",
      "Epoch 73......Step: 2/7....... Average Loss for Epoch: 0.0008127973560476676\n",
      "Epoch 73......Step: 3/7....... Average Loss for Epoch: 0.0006826667910596976\n",
      "Epoch 73......Step: 4/7....... Average Loss for Epoch: 0.0006275467676459812\n",
      "Epoch 73......Step: 5/7....... Average Loss for Epoch: 0.0005802980216685682\n",
      "Epoch 73......Step: 6/7....... Average Loss for Epoch: 0.0005982486230398839\n",
      "Epoch 73......Step: 7/7....... Average Loss for Epoch: 0.0005570022289508156\n",
      "Epoch 73/100 Done, Total Loss: 0.0005570022289508156\n",
      "Total Time Elapsed: 1.1875 seconds\n",
      "Epoch 74......Step: 1/7....... Average Loss for Epoch: 0.0002516512176953256\n",
      "Epoch 74......Step: 2/7....... Average Loss for Epoch: 0.0006586790841538459\n",
      "Epoch 74......Step: 3/7....... Average Loss for Epoch: 0.0005184356753791993\n",
      "Epoch 74......Step: 4/7....... Average Loss for Epoch: 0.0005394409563450608\n",
      "Epoch 74......Step: 5/7....... Average Loss for Epoch: 0.0005007143452530726\n",
      "Epoch 74......Step: 6/7....... Average Loss for Epoch: 0.0004996540446882136\n",
      "Epoch 74......Step: 7/7....... Average Loss for Epoch: 0.0005174354446353391\n",
      "Epoch 74/100 Done, Total Loss: 0.0005174354446353391\n",
      "Total Time Elapsed: 1.03125 seconds\n",
      "Epoch 75......Step: 1/7....... Average Loss for Epoch: 0.00032614910742267966\n",
      "Epoch 75......Step: 2/7....... Average Loss for Epoch: 0.0004844409122597426\n",
      "Epoch 75......Step: 3/7....... Average Loss for Epoch: 0.0006916538307753702\n",
      "Epoch 75......Step: 4/7....... Average Loss for Epoch: 0.0006014705650159158\n",
      "Epoch 75......Step: 5/7....... Average Loss for Epoch: 0.0005542395170778036\n",
      "Epoch 75......Step: 6/7....... Average Loss for Epoch: 0.0005393149137186507\n",
      "Epoch 75......Step: 7/7....... Average Loss for Epoch: 0.0005628976505249739\n",
      "Epoch 75/100 Done, Total Loss: 0.0005628976505249739\n",
      "Total Time Elapsed: 0.96875 seconds\n",
      "Epoch 76......Step: 1/7....... Average Loss for Epoch: 0.0005070620100013912\n",
      "Epoch 76......Step: 2/7....... Average Loss for Epoch: 0.0003716075007105246\n",
      "Epoch 76......Step: 3/7....... Average Loss for Epoch: 0.0004857085198940088\n",
      "Epoch 76......Step: 4/7....... Average Loss for Epoch: 0.00044944196997676045\n",
      "Epoch 76......Step: 5/7....... Average Loss for Epoch: 0.00047622190322726965\n",
      "Epoch 76......Step: 6/7....... Average Loss for Epoch: 0.0006307308406879505\n",
      "Epoch 76......Step: 7/7....... Average Loss for Epoch: 0.0006290486531465181\n",
      "Epoch 76/100 Done, Total Loss: 0.0006290486531465181\n",
      "Total Time Elapsed: 1.171875 seconds\n",
      "Epoch 77......Step: 1/7....... Average Loss for Epoch: 0.0008046035072766244\n",
      "Epoch 77......Step: 2/7....... Average Loss for Epoch: 0.0005233122792560607\n",
      "Epoch 77......Step: 3/7....... Average Loss for Epoch: 0.0004509036662057042\n",
      "Epoch 77......Step: 4/7....... Average Loss for Epoch: 0.0008290711266454309\n",
      "Epoch 77......Step: 5/7....... Average Loss for Epoch: 0.0007139388646464795\n",
      "Epoch 77......Step: 6/7....... Average Loss for Epoch: 0.0006502216613929098\n",
      "Epoch 77......Step: 7/7....... Average Loss for Epoch: 0.0005914305740069332\n",
      "Epoch 77/100 Done, Total Loss: 0.0005914305740069332\n",
      "Total Time Elapsed: 1.15625 seconds\n",
      "Epoch 78......Step: 1/7....... Average Loss for Epoch: 0.0005018123774789274\n",
      "Epoch 78......Step: 2/7....... Average Loss for Epoch: 0.0003519084639265202\n",
      "Epoch 78......Step: 3/7....... Average Loss for Epoch: 0.0005956441697586948\n",
      "Epoch 78......Step: 4/7....... Average Loss for Epoch: 0.0005523910695046652\n",
      "Epoch 78......Step: 5/7....... Average Loss for Epoch: 0.000489744040532969\n",
      "Epoch 78......Step: 6/7....... Average Loss for Epoch: 0.0004923968299408443\n",
      "Epoch 78......Step: 7/7....... Average Loss for Epoch: 0.0004400638530829123\n",
      "Epoch 78/100 Done, Total Loss: 0.0004400638530829123\n",
      "Total Time Elapsed: 1.3125 seconds\n",
      "Epoch 79......Step: 1/7....... Average Loss for Epoch: 0.00020677300926763564\n",
      "Epoch 79......Step: 2/7....... Average Loss for Epoch: 0.0004716834591818042\n",
      "Epoch 79......Step: 3/7....... Average Loss for Epoch: 0.00044276347519674647\n",
      "Epoch 79......Step: 4/7....... Average Loss for Epoch: 0.0004337715981819201\n",
      "Epoch 79......Step: 5/7....... Average Loss for Epoch: 0.00038292184472084046\n",
      "Epoch 79......Step: 6/7....... Average Loss for Epoch: 0.0005230084643699229\n",
      "Epoch 79......Step: 7/7....... Average Loss for Epoch: 0.0005091749356194798\n",
      "Epoch 79/100 Done, Total Loss: 0.0005091749356194798\n",
      "Total Time Elapsed: 1.078125 seconds\n",
      "Epoch 80......Step: 1/7....... Average Loss for Epoch: 0.00048392522148787975\n",
      "Epoch 80......Step: 2/7....... Average Loss for Epoch: 0.000798359455075115\n",
      "Epoch 80......Step: 3/7....... Average Loss for Epoch: 0.0007089700472230712\n",
      "Epoch 80......Step: 4/7....... Average Loss for Epoch: 0.0005966007520328276\n",
      "Epoch 80......Step: 5/7....... Average Loss for Epoch: 0.0005542363156564534\n",
      "Epoch 80......Step: 6/7....... Average Loss for Epoch: 0.0005070051071622098\n",
      "Epoch 80......Step: 7/7....... Average Loss for Epoch: 0.0004714878409036568\n",
      "Epoch 80/100 Done, Total Loss: 0.0004714878409036568\n",
      "Total Time Elapsed: 1.1875 seconds\n",
      "Epoch 81......Step: 1/7....... Average Loss for Epoch: 0.0011176057159900665\n",
      "Epoch 81......Step: 2/7....... Average Loss for Epoch: 0.0007070697902236134\n",
      "Epoch 81......Step: 3/7....... Average Loss for Epoch: 0.0005554947128985077\n",
      "Epoch 81......Step: 4/7....... Average Loss for Epoch: 0.0005291766865411773\n",
      "Epoch 81......Step: 5/7....... Average Loss for Epoch: 0.0004784207325428724\n",
      "Epoch 81......Step: 6/7....... Average Loss for Epoch: 0.00042917499619458493\n",
      "Epoch 81......Step: 7/7....... Average Loss for Epoch: 0.00044906068485163687\n",
      "Epoch 81/100 Done, Total Loss: 0.00044906068485163687\n",
      "Total Time Elapsed: 1.0625 seconds\n",
      "Epoch 82......Step: 1/7....... Average Loss for Epoch: 0.0010545693803578615\n",
      "Epoch 82......Step: 2/7....... Average Loss for Epoch: 0.0006723022670485079\n",
      "Epoch 82......Step: 3/7....... Average Loss for Epoch: 0.000515206430767042\n",
      "Epoch 82......Step: 4/7....... Average Loss for Epoch: 0.0004890925956715364\n",
      "Epoch 82......Step: 5/7....... Average Loss for Epoch: 0.00043480730673763903\n",
      "Epoch 82......Step: 6/7....... Average Loss for Epoch: 0.0004466602428389403\n",
      "Epoch 82......Step: 7/7....... Average Loss for Epoch: 0.00040999571293858547\n",
      "Epoch 82/100 Done, Total Loss: 0.00040999571293858547\n",
      "Total Time Elapsed: 1.0625 seconds\n",
      "Epoch 83......Step: 1/7....... Average Loss for Epoch: 0.0003003818274009973\n",
      "Epoch 83......Step: 2/7....... Average Loss for Epoch: 0.0004977570933988318\n",
      "Epoch 83......Step: 3/7....... Average Loss for Epoch: 0.00043751719446542364\n",
      "Epoch 83......Step: 4/7....... Average Loss for Epoch: 0.0006654132812400348\n",
      "Epoch 83......Step: 5/7....... Average Loss for Epoch: 0.0006454044894780963\n",
      "Epoch 83......Step: 6/7....... Average Loss for Epoch: 0.0006012982339598238\n",
      "Epoch 83......Step: 7/7....... Average Loss for Epoch: 0.0006201297593569117\n",
      "Epoch 83/100 Done, Total Loss: 0.0006201297593569117\n",
      "Total Time Elapsed: 1.21875 seconds\n",
      "Epoch 84......Step: 1/7....... Average Loss for Epoch: 0.0007125003030523658\n",
      "Epoch 84......Step: 2/7....... Average Loss for Epoch: 0.0008482834091410041\n",
      "Epoch 84......Step: 3/7....... Average Loss for Epoch: 0.0007134897944827875\n",
      "Epoch 84......Step: 4/7....... Average Loss for Epoch: 0.0006820427370257676\n",
      "Epoch 84......Step: 5/7....... Average Loss for Epoch: 0.0005965586402453482\n",
      "Epoch 84......Step: 6/7....... Average Loss for Epoch: 0.0005518986630098274\n",
      "Epoch 84......Step: 7/7....... Average Loss for Epoch: 0.0005085742866088237\n",
      "Epoch 84/100 Done, Total Loss: 0.0005085742866088237\n",
      "Total Time Elapsed: 1.171875 seconds\n",
      "Epoch 85......Step: 1/7....... Average Loss for Epoch: 0.00014907788136042655\n",
      "Epoch 85......Step: 2/7....... Average Loss for Epoch: 0.0007155289786169305\n",
      "Epoch 85......Step: 3/7....... Average Loss for Epoch: 0.0005992750423805168\n",
      "Epoch 85......Step: 4/7....... Average Loss for Epoch: 0.0005293519789120182\n",
      "Epoch 85......Step: 5/7....... Average Loss for Epoch: 0.00048523969599045813\n",
      "Epoch 85......Step: 6/7....... Average Loss for Epoch: 0.00048415956553071737\n",
      "Epoch 85......Step: 7/7....... Average Loss for Epoch: 0.0004786372883245349\n",
      "Epoch 85/100 Done, Total Loss: 0.0004786372883245349\n",
      "Total Time Elapsed: 1.21875 seconds\n",
      "Epoch 86......Step: 1/7....... Average Loss for Epoch: 0.0003025293117389083\n",
      "Epoch 86......Step: 2/7....... Average Loss for Epoch: 0.0002506889359210618\n",
      "Epoch 86......Step: 3/7....... Average Loss for Epoch: 0.00029482346629568684\n",
      "Epoch 86......Step: 4/7....... Average Loss for Epoch: 0.0003177538419549819\n",
      "Epoch 86......Step: 5/7....... Average Loss for Epoch: 0.0004583230678690597\n",
      "Epoch 86......Step: 6/7....... Average Loss for Epoch: 0.0005168404968571849\n",
      "Epoch 86......Step: 7/7....... Average Loss for Epoch: 0.0004693028687532725\n",
      "Epoch 86/100 Done, Total Loss: 0.0004693028687532725\n",
      "Total Time Elapsed: 1.234375 seconds\n",
      "Epoch 87......Step: 1/7....... Average Loss for Epoch: 0.00020049186423420906\n",
      "Epoch 87......Step: 2/7....... Average Loss for Epoch: 0.0003717973886523396\n",
      "Epoch 87......Step: 3/7....... Average Loss for Epoch: 0.00035825315474842984\n",
      "Epoch 87......Step: 4/7....... Average Loss for Epoch: 0.0003227147681172937\n",
      "Epoch 87......Step: 5/7....... Average Loss for Epoch: 0.00039416891522705557\n",
      "Epoch 87......Step: 6/7....... Average Loss for Epoch: 0.0004086541545499737\n",
      "Epoch 87......Step: 7/7....... Average Loss for Epoch: 0.00041648610827646086\n",
      "Epoch 87/100 Done, Total Loss: 0.00041648610827646086\n",
      "Total Time Elapsed: 1.203125 seconds\n",
      "Epoch 88......Step: 1/7....... Average Loss for Epoch: 0.000339590449584648\n",
      "Epoch 88......Step: 2/7....... Average Loss for Epoch: 0.0005697534215869382\n",
      "Epoch 88......Step: 3/7....... Average Loss for Epoch: 0.0004267629313593109\n",
      "Epoch 88......Step: 4/7....... Average Loss for Epoch: 0.0004939847567584366\n",
      "Epoch 88......Step: 5/7....... Average Loss for Epoch: 0.0006095876917243004\n",
      "Epoch 88......Step: 6/7....... Average Loss for Epoch: 0.0005687379307346418\n",
      "Epoch 88......Step: 7/7....... Average Loss for Epoch: 0.0005295258098548013\n",
      "Epoch 88/100 Done, Total Loss: 0.0005295258098548013\n",
      "Total Time Elapsed: 1.125 seconds\n",
      "Epoch 89......Step: 1/7....... Average Loss for Epoch: 0.0006741716642864048\n",
      "Epoch 89......Step: 2/7....... Average Loss for Epoch: 0.0009609780681785196\n",
      "Epoch 89......Step: 3/7....... Average Loss for Epoch: 0.000752891122829169\n",
      "Epoch 89......Step: 4/7....... Average Loss for Epoch: 0.0006248247809708118\n",
      "Epoch 89......Step: 5/7....... Average Loss for Epoch: 0.0005819290701765567\n",
      "Epoch 89......Step: 6/7....... Average Loss for Epoch: 0.0005380486400099471\n",
      "Epoch 89......Step: 7/7....... Average Loss for Epoch: 0.000512451577898381\n",
      "Epoch 89/100 Done, Total Loss: 0.000512451577898381\n",
      "Total Time Elapsed: 1.046875 seconds\n",
      "Epoch 90......Step: 1/7....... Average Loss for Epoch: 0.00029319614986889064\n",
      "Epoch 90......Step: 2/7....... Average Loss for Epoch: 0.0003178142796969041\n",
      "Epoch 90......Step: 3/7....... Average Loss for Epoch: 0.00042758745257742703\n",
      "Epoch 90......Step: 4/7....... Average Loss for Epoch: 0.00040990834531839937\n",
      "Epoch 90......Step: 5/7....... Average Loss for Epoch: 0.0004109545436222106\n",
      "Epoch 90......Step: 6/7....... Average Loss for Epoch: 0.0004544535913737491\n",
      "Epoch 90......Step: 7/7....... Average Loss for Epoch: 0.00042746273850622984\n",
      "Epoch 90/100 Done, Total Loss: 0.00042746273850622984\n",
      "Total Time Elapsed: 1.203125 seconds\n",
      "Epoch 91......Step: 1/7....... Average Loss for Epoch: 0.00025866011856123805\n",
      "Epoch 91......Step: 2/7....... Average Loss for Epoch: 0.0002445218415232375\n",
      "Epoch 91......Step: 3/7....... Average Loss for Epoch: 0.0002103325726542001\n",
      "Epoch 91......Step: 4/7....... Average Loss for Epoch: 0.00019848705778713338\n",
      "Epoch 91......Step: 5/7....... Average Loss for Epoch: 0.00022369812650140374\n",
      "Epoch 91......Step: 6/7....... Average Loss for Epoch: 0.0002932517939674047\n",
      "Epoch 91......Step: 7/7....... Average Loss for Epoch: 0.0004260164382035977\n",
      "Epoch 91/100 Done, Total Loss: 0.0004260164382035977\n",
      "Total Time Elapsed: 1.015625 seconds\n",
      "Epoch 92......Step: 1/7....... Average Loss for Epoch: 0.00017612631199881434\n",
      "Epoch 92......Step: 2/7....... Average Loss for Epoch: 0.0004947952984366566\n",
      "Epoch 92......Step: 3/7....... Average Loss for Epoch: 0.0003945940067448343\n",
      "Epoch 92......Step: 4/7....... Average Loss for Epoch: 0.0003918040056305472\n",
      "Epoch 92......Step: 5/7....... Average Loss for Epoch: 0.0005153619247721508\n",
      "Epoch 92......Step: 6/7....... Average Loss for Epoch: 0.0004911116387423439\n",
      "Epoch 92......Step: 7/7....... Average Loss for Epoch: 0.0004419061234719785\n",
      "Epoch 92/100 Done, Total Loss: 0.0004419061234719785\n",
      "Total Time Elapsed: 1.203125 seconds\n",
      "Epoch 93......Step: 1/7....... Average Loss for Epoch: 0.0007559570949524641\n",
      "Epoch 93......Step: 2/7....... Average Loss for Epoch: 0.000503478673635982\n",
      "Epoch 93......Step: 3/7....... Average Loss for Epoch: 0.0004285281465854496\n",
      "Epoch 93......Step: 4/7....... Average Loss for Epoch: 0.0005500672923517413\n",
      "Epoch 93......Step: 5/7....... Average Loss for Epoch: 0.0005176727077923715\n",
      "Epoch 93......Step: 6/7....... Average Loss for Epoch: 0.0004486940997594502\n",
      "Epoch 93......Step: 7/7....... Average Loss for Epoch: 0.00042182950606469864\n",
      "Epoch 93/100 Done, Total Loss: 0.00042182950606469864\n",
      "Total Time Elapsed: 1.25 seconds\n",
      "Epoch 94......Step: 1/7....... Average Loss for Epoch: 0.00016222152044065297\n",
      "Epoch 94......Step: 2/7....... Average Loss for Epoch: 0.0006091591931181028\n",
      "Epoch 94......Step: 3/7....... Average Loss for Epoch: 0.0004898870926505575\n",
      "Epoch 94......Step: 4/7....... Average Loss for Epoch: 0.00042539689093246125\n",
      "Epoch 94......Step: 5/7....... Average Loss for Epoch: 0.00037832186208106575\n",
      "Epoch 94......Step: 6/7....... Average Loss for Epoch: 0.0004145493294345215\n",
      "Epoch 94......Step: 7/7....... Average Loss for Epoch: 0.0004703408132107662\n",
      "Epoch 94/100 Done, Total Loss: 0.0004703408132107662\n",
      "Total Time Elapsed: 1.03125 seconds\n",
      "Epoch 95......Step: 1/7....... Average Loss for Epoch: 0.00022457836894318461\n",
      "Epoch 95......Step: 2/7....... Average Loss for Epoch: 0.00021010550699429587\n",
      "Epoch 95......Step: 3/7....... Average Loss for Epoch: 0.00037020839226897806\n",
      "Epoch 95......Step: 4/7....... Average Loss for Epoch: 0.0003301658471173141\n",
      "Epoch 95......Step: 5/7....... Average Loss for Epoch: 0.00033136445854324846\n",
      "Epoch 95......Step: 6/7....... Average Loss for Epoch: 0.0003260290128916192\n",
      "Epoch 95......Step: 7/7....... Average Loss for Epoch: 0.0004665009141068107\n",
      "Epoch 95/100 Done, Total Loss: 0.0004665009141068107\n",
      "Total Time Elapsed: 1.15625 seconds\n",
      "Epoch 96......Step: 1/7....... Average Loss for Epoch: 0.00048764306120574474\n",
      "Epoch 96......Step: 2/7....... Average Loss for Epoch: 0.0003674068721011281\n",
      "Epoch 96......Step: 3/7....... Average Loss for Epoch: 0.0003329054646504422\n",
      "Epoch 96......Step: 4/7....... Average Loss for Epoch: 0.0002712027526285965\n",
      "Epoch 96......Step: 5/7....... Average Loss for Epoch: 0.00029307367803994567\n",
      "Epoch 96......Step: 6/7....... Average Loss for Epoch: 0.00046412081428570673\n",
      "Epoch 96......Step: 7/7....... Average Loss for Epoch: 0.00044295484258327633\n",
      "Epoch 96/100 Done, Total Loss: 0.00044295484258327633\n",
      "Total Time Elapsed: 1.09375 seconds\n",
      "Epoch 97......Step: 1/7....... Average Loss for Epoch: 0.0002710132102947682\n",
      "Epoch 97......Step: 2/7....... Average Loss for Epoch: 0.00024631022824905813\n",
      "Epoch 97......Step: 3/7....... Average Loss for Epoch: 0.0005632203343945245\n",
      "Epoch 97......Step: 4/7....... Average Loss for Epoch: 0.0005169370124349371\n",
      "Epoch 97......Step: 5/7....... Average Loss for Epoch: 0.0004995288094505667\n",
      "Epoch 97......Step: 6/7....... Average Loss for Epoch: 0.00046698908651402843\n",
      "Epoch 97......Step: 7/7....... Average Loss for Epoch: 0.0004209564212942496\n",
      "Epoch 97/100 Done, Total Loss: 0.0004209564212942496\n",
      "Total Time Elapsed: 1.234375 seconds\n",
      "Epoch 98......Step: 1/7....... Average Loss for Epoch: 0.0001384819915983826\n",
      "Epoch 98......Step: 2/7....... Average Loss for Epoch: 0.0004382239858387038\n",
      "Epoch 98......Step: 3/7....... Average Loss for Epoch: 0.0007111049781087786\n",
      "Epoch 98......Step: 4/7....... Average Loss for Epoch: 0.0005604779125860659\n",
      "Epoch 98......Step: 5/7....... Average Loss for Epoch: 0.0005088392164907419\n",
      "Epoch 98......Step: 6/7....... Average Loss for Epoch: 0.0004563678752068275\n",
      "Epoch 98......Step: 7/7....... Average Loss for Epoch: 0.00043605041303505587\n",
      "Epoch 98/100 Done, Total Loss: 0.00043605041303505587\n",
      "Total Time Elapsed: 1.03125 seconds\n",
      "Epoch 99......Step: 1/7....... Average Loss for Epoch: 0.00023180241987574846\n",
      "Epoch 99......Step: 2/7....... Average Loss for Epoch: 0.0003011902081198059\n",
      "Epoch 99......Step: 3/7....... Average Loss for Epoch: 0.0002543199807405472\n",
      "Epoch 99......Step: 4/7....... Average Loss for Epoch: 0.00028509720868896693\n",
      "Epoch 99......Step: 5/7....... Average Loss for Epoch: 0.0003333549713715911\n",
      "Epoch 99......Step: 6/7....... Average Loss for Epoch: 0.00030292953306343406\n",
      "Epoch 99......Step: 7/7....... Average Loss for Epoch: 0.0002927849667945078\n",
      "Epoch 99/100 Done, Total Loss: 0.0002927849667945078\n",
      "Total Time Elapsed: 1.171875 seconds\n",
      "Epoch 100......Step: 1/7....... Average Loss for Epoch: 0.0005437266081571579\n",
      "Epoch 100......Step: 2/7....... Average Loss for Epoch: 0.0003565827792044729\n",
      "Epoch 100......Step: 3/7....... Average Loss for Epoch: 0.00031182914002177614\n",
      "Epoch 100......Step: 4/7....... Average Loss for Epoch: 0.00028688924066955224\n",
      "Epoch 100......Step: 5/7....... Average Loss for Epoch: 0.0003408566175494343\n",
      "Epoch 100......Step: 6/7....... Average Loss for Epoch: 0.0003314945982613911\n",
      "Epoch 100......Step: 7/7....... Average Loss for Epoch: 0.0004451186645642987\n",
      "Epoch 100/100 Done, Total Loss: 0.0004451186645642987\n",
      "Total Time Elapsed: 1.1875 seconds\n",
      "Total Training Time: 110.953125 seconds\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "gru_model = train(train_loader, lr, model_type=\"GRU\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Time: 0.078125\n",
      "sMAPE: 0.5571775456072083%\n"
     ]
    }
   ],
   "source": [
    "gru_outputs, targets, gru_sMAPE = evaluate(gru_model, test_x, test_y, label_sc)\n",
    "\n",
    "# MAE and RMSE\n",
    "# predicted curve\n",
    "# performance, numerical results\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([0.9026593 , 0.89882606, 0.8949764 , 0.8911573 , 0.8873884 ,\n        0.88370246, 0.8800462 , 0.8763732 , 0.8725236 , 0.868451  ,\n        0.8642456 , 0.86001706, 0.8557459 , 0.85170954, 0.84783536,\n        0.84403205, 0.84021604, 0.83642256, 0.8327471 , 0.8292339 ,\n        0.8258159 , 0.82266694, 0.81955886, 0.81639653, 0.813291  ,\n        0.81021637, 0.8071416 , 0.8042205 , 0.80077976, 0.79752535,\n        0.79470545, 0.79200536, 0.7891512 , 0.78637683, 0.7835565 ,\n        0.78065723, 0.7776628 , 0.77488816, 0.7722649 , 0.7697011 ,\n        0.7444099 ], dtype=float32)]"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x2019842e800>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1400x1000 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(gru_outputs[0][-100:], \"-o\", color=\"g\", label=\"Predicted\")\n",
    "plt.plot(targets[0][-100:], color=\"b\", label=\"Actual\")\n",
    "plt.ylabel('soh')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "abb986b297a1e39e4a9784cac1041b65609e2eefd57e07e1d90a430925bc2fc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
