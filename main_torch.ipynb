{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import warnings\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('Oxford_Battery_Degradation_Dataset_1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['__header__', '__version__', '__globals__', 'Cell1', 'Cell2', 'Cell3', 'Cell4', 'Cell5', 'Cell6', 'Cell7', 'Cell8'])"
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "outputs": [],
   "source": [
    "input_data = [\n",
    "    [[], []],\n",
    "    [[], []],\n",
    "    [[], []],\n",
    "    [[], []],\n",
    "    [[], []]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "724.1208914093187\n",
      "714.5350426825697\n",
      "709.8543464961379\n",
      "707.0393485194566\n",
      "702.2342863457235\n",
      "698.8440013150872\n",
      "695.4850715278354\n",
      "691.6932258285015\n",
      "687.6300422440017\n",
      "684.2488065128581\n",
      "681.0607272448832\n",
      "677.8486336050008\n",
      "674.7281887527703\n",
      "671.556081370731\n",
      "668.6709791990864\n",
      "nan\n",
      "662.9724287937147\n",
      "nan\n",
      "656.4621886431951\n",
      "653.2751603988444\n",
      "650.1157422984008\n",
      "647.1105116933119\n",
      "644.0549444561768\n",
      "640.7948747304991\n",
      "638.1391374235501\n",
      "635.3790871886936\n",
      "632.3887851445143\n",
      "629.9572173218418\n",
      "627.3439847566834\n",
      "624.1095617381898\n",
      "622.448908879052\n",
      "619.9778349196439\n",
      "617.3031788485108\n",
      "615.3476618618469\n",
      "nan\n",
      "611.340570310974\n",
      "609.7195455723199\n",
      "605.1998563440754\n",
      "604.1349210491537\n",
      "602.8723865926853\n",
      "600.9075598059693\n",
      "598.2787878589917\n",
      "596.7047192299974\n",
      "594.08713143121\n",
      "591.9284795739374\n",
      "589.3588371850756\n",
      "588.0833074787903\n",
      "nan\n",
      "584.2617834340922\n",
      "nan\n",
      "579.5968326875441\n",
      "577.6717759357741\n",
      "575.5147033984103\n",
      "574.7467034891866\n",
      "572.8103356272312\n",
      "568.9614464139573\n",
      "568.632337365943\n",
      "566.7898372362026\n",
      "564.7710880962863\n",
      "563.0229675191888\n",
      "561.5319859533353\n",
      "559.0240164641148\n",
      "558.9932350188666\n",
      "557.2408422441746\n",
      "554.0352644300469\n",
      "554.4326746213887\n",
      "552.5936740321791\n",
      "550.9885335174934\n",
      "550.4593525596042\n",
      "549.1350762103983\n",
      "545.1952021221653\n",
      "545.1952021221653\n",
      "545.2029575675828\n",
      "543.6705120329285\n",
      "541.9178534255642\n",
      "539.6733627491049\n",
      "538.7682346467591\n",
      "537.5784986630249\n",
      "534.7154670857103\n",
      "534.7317288957756\n",
      "533.2962153664076\n",
      "529.4571383120897\n",
      "530.5961183990717\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 83):\n",
    "    if (i < 10):\n",
    "        if (i == 0):\n",
    "            temp = \"cyc0000\"\n",
    "        else:\n",
    "            temp = \"cyc0\" + str(i) + \"00\"\n",
    "    else:\n",
    "        temp = \"cyc\" + str(i) + \"00\"\n",
    "    try:\n",
    "        curr = mat[\"Cell1\"][0][temp][0][0][\"C1ch\"][0][0]['q'][0][-1][0]\n",
    "    except ValueError:\n",
    "        curr = float(\"NaN\")\n",
    "    input_data[0][0].append(i)\n",
    "    input_data[0][1].append(curr)\n",
    "    print(curr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718.741297925537\n",
      "709.5681071291199\n",
      "704.9058163403389\n",
      "702.3456149198066\n",
      "697.1368473715753\n",
      "693.5280529826321\n",
      "690.2526227546354\n",
      "687.9312178554381\n",
      "683.9562011113857\n",
      "681.1490369562412\n",
      "678.4389754590828\n",
      "675.6869704751757\n",
      "672.6909481645915\n",
      "669.6118516598985\n",
      "666.6693579710898\n",
      "nan\n",
      "661.0438750956963\n",
      "nan\n",
      "654.8732928540276\n",
      "651.5763009192572\n",
      "648.0620407410753\n",
      "645.0273202361824\n",
      "641.9561587872146\n",
      "639.1817874060634\n",
      "636.146987355567\n",
      "633.5869444285584\n",
      "630.2719502065734\n",
      "628.4404882446424\n",
      "625.6947332317742\n",
      "621.4573128423089\n",
      "620.0355903464084\n",
      "617.0226657589787\n",
      "613.529064392273\n",
      "611.8853332623833\n",
      "nan\n",
      "606.7991489488695\n",
      "606.1075187611355\n",
      "602.0501712794936\n",
      "599.804125769962\n",
      "599.062711397054\n",
      "596.8222385493266\n",
      "593.1072435700955\n",
      "591.9062524962668\n",
      "589.1572257318285\n",
      "586.90617990074\n",
      "583.6450163602024\n",
      "582.6071782655945\n",
      "nan\n",
      "578.5371559859686\n",
      "nan\n",
      "540.1406011361898\n",
      "544.1508260616624\n",
      "543.2743302246569\n",
      "546.5392956914469\n",
      "546.5661247950405\n",
      "541.5460386269837\n",
      "544.325896470876\n",
      "543.3293544748332\n",
      "541.0781344591743\n",
      "539.873856048689\n",
      "538.0126744202508\n",
      "531.7941460643989\n",
      "535.3074075393235\n",
      "533.4260004740635\n",
      "526.255781204539\n",
      "530.2883048969014\n",
      "528.0916532404514\n",
      "529.1747535864461\n",
      "529.2633184395921\n",
      "527.0825452443813\n",
      "519.7201222548049\n",
      "520.7728065731033\n",
      "520.644083452423\n",
      "520.4910665838386\n",
      "475.4615621634386\n",
      "524.5923459845818\n",
      "520.708630040836\n",
      "505.7172067723219\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 78):\n",
    "    if (i < 10):\n",
    "        if (i == 0):\n",
    "            temp = \"cyc0000\"\n",
    "        else:\n",
    "            temp = \"cyc0\" + str(i) + \"00\"\n",
    "    else:\n",
    "        temp = \"cyc\" + str(i) + \"00\"\n",
    "    try:\n",
    "        curr = mat[\"Cell2\"][0][temp][0][0][\"C1ch\"][0][0]['q'][0][-1][0]\n",
    "    except ValueError:\n",
    "        curr = float(\"NaN\")\n",
    "    input_data[1][0].append(i)\n",
    "    input_data[1][1].append(curr)\n",
    "    print(curr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718.7631395299276\n",
      "709.773752809004\n",
      "705.5003496343891\n",
      "703.179715527476\n",
      "698.6793038556247\n",
      "695.5755666377021\n",
      "692.6804139407959\n",
      "690.9952733899265\n",
      "687.6160393374396\n",
      "685.1340395459562\n",
      "682.7033126399366\n",
      "680.3608812850377\n",
      "677.9297546952447\n",
      "675.3622352245551\n",
      "672.7948973098858\n",
      "nan\n",
      "667.860750732734\n",
      "nan\n",
      "661.9469030268589\n",
      "659.0533480837539\n",
      "656.1259535114813\n",
      "653.263523338667\n",
      "650.3072266254272\n",
      "647.5960743479478\n",
      "645.107360001024\n",
      "642.2626477255825\n",
      "639.4436417116023\n",
      "637.2262217119649\n",
      "634.4764265170153\n",
      "631.2939332858479\n",
      "629.3235018324585\n",
      "626.7830689711067\n",
      "623.7088201648356\n",
      "nan\n",
      "nan\n",
      "617.4528684451836\n",
      "615.911979257036\n",
      "612.2898770856086\n",
      "611.157118682434\n",
      "609.5205118533969\n",
      "607.1033436763611\n",
      "604.5793552813755\n",
      "603.0115005746461\n",
      "600.4328458881564\n",
      "598.2719965298292\n",
      "595.341309710907\n",
      "593.3874599997288\n",
      "nan\n",
      "589.3170987658963\n",
      "nan\n",
      "584.5440061324972\n",
      "582.3691352973802\n",
      "580.2034366532152\n",
      "579.2706408033243\n",
      "577.1580542297907\n",
      "574.2643660177985\n",
      "573.836394326867\n",
      "571.993239701155\n",
      "569.9563823112692\n",
      "567.7289925591532\n",
      "565.7341881581184\n",
      "562.8485649205356\n",
      "562.1106181763713\n",
      "560.2828756706916\n",
      "557.7023096802334\n",
      "557.3780737668898\n",
      "555.605335234826\n",
      "556.1283910736762\n",
      "555.6865693176168\n",
      "553.9327553975932\n",
      "551.0498874523112\n",
      "551.1722640103184\n",
      "549.4368309830695\n",
      "547.6232288894925\n",
      "545.7595240120578\n",
      "544.3290846505059\n",
      "542.6947330667623\n",
      "540.5556469268324\n",
      "539.8710663800355\n",
      "538.352942506507\n",
      "536.0941143807577\n",
      "535.9892378836468\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 82):\n",
    "    if (i < 10):\n",
    "        if (i == 0):\n",
    "            temp = \"cyc0000\"\n",
    "        else:\n",
    "            temp = \"cyc0\" + str(i) + \"00\"\n",
    "    else:\n",
    "        temp = \"cyc\" + str(i) + \"00\"\n",
    "    try:\n",
    "        curr = mat[\"Cell3\"][0][temp][0][0][\"C1ch\"][0][0]['q'][0][-1][0]\n",
    "    except ValueError:\n",
    "        curr = float(\"NaN\")\n",
    "    input_data[2][0].append(i)\n",
    "    input_data[2][1].append(curr)\n",
    "    print(curr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721.1164843827853\n",
      "712.0679318298407\n",
      "706.9871122118395\n",
      "703.2141196563043\n",
      "697.5632033832364\n",
      "693.4313661446499\n",
      "689.3232259051073\n",
      "684.6806726656562\n",
      "680.5215711629673\n",
      "676.9138722703382\n",
      "673.1332688880785\n",
      "669.254472952847\n",
      "664.8751990971984\n",
      "660.7292772686156\n",
      "656.5154255277236\n",
      "nan\n",
      "649.0225222257487\n",
      "nan\n",
      "640.7433987497865\n",
      "636.9393948052233\n",
      "632.8373748397114\n",
      "629.3621179469435\n",
      "625.420070599918\n",
      "622.5492503774007\n",
      "619.9996876792127\n",
      "617.2418496067268\n",
      "612.966908147973\n",
      "610.5559912618273\n",
      "608.2378642040067\n",
      "604.1494928159519\n",
      "602.7136125503912\n",
      "599.4423191019187\n",
      "596.2102732655708\n",
      "594.6531594138828\n",
      "nan\n",
      "589.2581597436352\n",
      "587.3144895586956\n",
      "582.3196168509047\n",
      "580.8840633218181\n",
      "580.0492210948012\n",
      "578.2639342326898\n",
      "574.0774628077731\n",
      "572.8297306677382\n",
      "570.1357001743164\n",
      "568.1299646968248\n",
      "564.5128975512729\n",
      "563.6108884776035\n",
      "nan\n",
      "559.8291404311693\n",
      "nan\n",
      "557.4281094756539\n",
      "555.5754281423713\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 52):\n",
    "    if (i < 10):\n",
    "        if (i == 0):\n",
    "            temp = \"cyc0000\"\n",
    "        else:\n",
    "            temp = \"cyc0\" + str(i) + \"00\"\n",
    "    else:\n",
    "        temp = \"cyc\" + str(i) + \"00\"\n",
    "    try:\n",
    "        curr = mat[\"Cell4\"][0][temp][0][0][\"C1ch\"][0][0]['q'][0][-1][0]\n",
    "    except ValueError:\n",
    "        curr = float(\"NaN\")\n",
    "    input_data[3][0].append(i)\n",
    "    input_data[3][1].append(curr)\n",
    "    print(curr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720.4058178135612\n",
      "710.52023571817\n",
      "705.3694592736239\n",
      "702.4368025946926\n",
      "696.9903605962321\n",
      "693.1378749817198\n",
      "689.7118647878282\n",
      "687.3714642827997\n",
      "683.4967846410217\n",
      "680.4886010656434\n",
      "677.651149840505\n",
      "674.5533586915826\n",
      "671.6860353622606\n",
      "668.8064564948561\n",
      "666.0877797769302\n",
      "nan\n",
      "660.3256382438456\n",
      "nan\n",
      "653.7171921344435\n",
      "650.5809573330891\n",
      "647.4186945669657\n",
      "644.1002161796841\n",
      "641.5899401395433\n",
      "638.613594611596\n",
      "635.6849274886135\n",
      "632.7146078182034\n",
      "629.943362580763\n",
      "627.3842809751994\n",
      "624.8940165767923\n",
      "622.2811819499681\n",
      "620.3946293587749\n",
      "617.7221195575528\n",
      "615.2191850532023\n",
      "613.124334611969\n",
      "nan\n",
      "608.3997513125915\n",
      "606.5584273187087\n",
      "602.5035575975069\n",
      "601.4283003763225\n",
      "599.7926490444471\n",
      "597.2795841821526\n",
      "594.6691204956426\n",
      "593.0807431121385\n",
      "590.6419559054871\n",
      "588.3435470161472\n",
      "585.9745001529541\n",
      "584.5228092373318\n",
      "nan\n",
      "580.4344153968913\n",
      "nan\n",
      "430.9063537073466\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 51):\n",
    "    if (i < 10):\n",
    "        if (i == 0):\n",
    "            temp = \"cyc0000\"\n",
    "        else:\n",
    "            temp = \"cyc0\" + str(i) + \"00\"\n",
    "    else:\n",
    "        temp = \"cyc\" + str(i) + \"00\"\n",
    "    try:\n",
    "        curr = mat[\"Cell5\"][0][temp][0][0][\"C1ch\"][0][0]['q'][0][-1][0]\n",
    "    except ValueError:\n",
    "        curr = float(\"NaN\")\n",
    "    input_data[4][0].append(i)\n",
    "    input_data[4][1].append(curr)\n",
    "    print(curr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "outputs": [],
   "source": [
    "label_scalers = {}\n",
    "\n",
    "train_x = []\n",
    "test_x = []\n",
    "test_y = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "[[[1.        ]\n",
      "  [0.95075689]\n",
      "  [0.92671186]\n",
      "  [0.91225103]\n",
      "  [0.88756713]\n",
      "  [0.87015102]\n",
      "  [0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]]\n",
      "\n",
      " [[0.95075689]\n",
      "  [0.92671186]\n",
      "  [0.91225103]\n",
      "  [0.88756713]\n",
      "  [0.87015102]\n",
      "  [0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]]\n",
      "\n",
      " [[0.92671186]\n",
      "  [0.91225103]\n",
      "  [0.88756713]\n",
      "  [0.87015102]\n",
      "  [0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]]\n",
      "\n",
      " [[0.91225103]\n",
      "  [0.88756713]\n",
      "  [0.87015102]\n",
      "  [0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]]\n",
      "\n",
      " [[0.88756713]\n",
      "  [0.87015102]\n",
      "  [0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]]\n",
      "\n",
      " [[0.87015102]\n",
      "  [0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]]\n",
      "\n",
      " [[0.85289598]\n",
      "  [0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]]\n",
      "\n",
      " [[0.83341703]\n",
      "  [0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]]\n",
      "\n",
      " [[0.8125442 ]\n",
      "  [0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]]\n",
      "\n",
      " [[0.79517458]\n",
      "  [0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]]\n",
      "\n",
      " [[0.77879722]\n",
      "  [0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]]\n",
      "\n",
      " [[0.76229649]\n",
      "  [0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]]\n",
      "\n",
      " [[0.74626657]\n",
      "  [0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]]\n",
      "\n",
      " [[0.72997125]\n",
      "  [0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]]\n",
      "\n",
      " [[0.7151503 ]\n",
      "  [0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]]\n",
      "\n",
      " [[0.70051339]\n",
      "  [0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]]\n",
      "\n",
      " [[0.68587648]\n",
      "  [0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]]\n",
      "\n",
      " [[0.66915473]\n",
      "  [0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]]\n",
      "\n",
      " [[0.65243297]\n",
      "  [0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]]\n",
      "\n",
      " [[0.636061  ]\n",
      "  [0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]]\n",
      "\n",
      " [[0.61983087]\n",
      "  [0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]]\n",
      "\n",
      " [[0.60439281]\n",
      "  [0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]]\n",
      "\n",
      " [[0.58869617]\n",
      "  [0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]]\n",
      "\n",
      " [[0.57194899]\n",
      "  [0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]]\n",
      "\n",
      " [[0.5583063 ]\n",
      "  [0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]]\n",
      "\n",
      " [[0.54412774]\n",
      "  [0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]]\n",
      "\n",
      " [[0.52876637]\n",
      "  [0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]]\n",
      "\n",
      " [[0.51627526]\n",
      "  [0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]]\n",
      "\n",
      " [[0.50285092]\n",
      "  [0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]]\n",
      "\n",
      " [[0.48623548]\n",
      "  [0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]]\n",
      "\n",
      " [[0.4777046 ]\n",
      "  [0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]]\n",
      "\n",
      " [[0.46501054]\n",
      "  [0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]]\n",
      "\n",
      " [[0.45127066]\n",
      "  [0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]]\n",
      "\n",
      " [[0.44122505]\n",
      "  [0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]]\n",
      "\n",
      " [[0.43093271]\n",
      "  [0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]]\n",
      "\n",
      " [[0.42064036]\n",
      "  [0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]]\n",
      "\n",
      " [[0.41231306]\n",
      "  [0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]]\n",
      "\n",
      " [[0.38909513]\n",
      "  [0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]]\n",
      "\n",
      " [[0.38362449]\n",
      "  [0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]]\n",
      "\n",
      " [[0.37713877]\n",
      "  [0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]]\n",
      "\n",
      " [[0.36704533]\n",
      "  [0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]]\n",
      "\n",
      " [[0.35354116]\n",
      "  [0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]]\n",
      "\n",
      " [[0.34545507]\n",
      "  [0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]]\n",
      "\n",
      " [[0.33200836]\n",
      "  [0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]]\n",
      "\n",
      " [[0.32091923]\n",
      "  [0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]]\n",
      "\n",
      " [[0.30771881]\n",
      "  [0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]]\n",
      "\n",
      " [[0.30116634]\n",
      "  [0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]]\n",
      "\n",
      " [[0.29135063]\n",
      "  [0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]]\n",
      "\n",
      " [[0.28153492]\n",
      "  [0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]]\n",
      "\n",
      " [[0.26955285]\n",
      "  [0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]]\n",
      "\n",
      " [[0.25757078]\n",
      "  [0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]]\n",
      "\n",
      " [[0.24768164]\n",
      "  [0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]]\n",
      "\n",
      " [[0.23660062]\n",
      "  [0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]]\n",
      "\n",
      " [[0.23265536]\n",
      "  [0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]]\n",
      "\n",
      " [[0.22270811]\n",
      "  [0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]]\n",
      "\n",
      " [[0.20293613]\n",
      "  [0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]]\n",
      "\n",
      " [[0.20124547]\n",
      "  [0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]]\n",
      "\n",
      " [[0.19178043]\n",
      "  [0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]]\n",
      "\n",
      " [[0.18140999]\n",
      "  [0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]]\n",
      "\n",
      " [[0.17242979]\n",
      "  [0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]]\n",
      "\n",
      " [[0.16477052]\n",
      "  [0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]]\n",
      "\n",
      " [[0.15188692]\n",
      "  [0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]]\n",
      "\n",
      " [[0.1517288 ]\n",
      "  [0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]]\n",
      "\n",
      " [[0.14272664]\n",
      "  [0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]]\n",
      "\n",
      " [[0.12625939]\n",
      "  [0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]]\n",
      "\n",
      " [[0.12830091]\n",
      "  [0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]]\n",
      "\n",
      " [[0.11885385]\n",
      "  [0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]]\n",
      "\n",
      " [[0.11060814]\n",
      "  [0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]\n",
      "  [0.04783169]]\n",
      "\n",
      " [[0.1078897 ]\n",
      "  [0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]\n",
      "  [0.04783169]\n",
      "  [0.04171994]]\n",
      "\n",
      " [[0.10108681]\n",
      "  [0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]\n",
      "  [0.04783169]\n",
      "  [0.04171994]\n",
      "  [0.02701237]]\n",
      "\n",
      " [[0.08084743]\n",
      "  [0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]\n",
      "  [0.04783169]\n",
      "  [0.04171994]\n",
      "  [0.02701237]\n",
      "  [0.02709591]]\n",
      "\n",
      " [[0.08084743]\n",
      "  [0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]\n",
      "  [0.04783169]\n",
      "  [0.04171994]\n",
      "  [0.02701237]\n",
      "  [0.02709591]\n",
      "  [0.01972158]]\n",
      "\n",
      " [[0.08088727]\n",
      "  [0.073015  ]\n",
      "  [0.06401148]\n",
      "  [0.05248139]\n",
      "  [0.04783169]\n",
      "  [0.04171994]\n",
      "  [0.02701237]\n",
      "  [0.02709591]\n",
      "  [0.01972158]\n",
      "  [0.        ]]]\n",
      "---\n",
      "---\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "\n",
    "for i in range(0, 5):\n",
    "    df_input = pd.DataFrame(input_data[i]).transpose()\n",
    "    df_input = df_input.rename(columns={0: \"cycle\", 1: \"q_value\"})\n",
    "    df_input['interpolate_spline'] = df_input['q_value'].interpolate(option='spline')\n",
    "    df_input['soh'] = df_input['interpolate_spline'] / 740\n",
    "\n",
    "    df_input = df_input.drop(\"cycle\", axis=1)\n",
    "    df_input = df_input.drop(\"q_value\", axis=1)\n",
    "    df_input = df_input.drop(\"interpolate_spline\", axis=1)\n",
    "\n",
    "    sc = MinMaxScaler()\n",
    "    label_sc = MinMaxScaler()\n",
    "    data = sc.fit_transform(df_input.values)\n",
    "    label_sc.fit(df_input.iloc[:, 0].values.reshape(-1, 1))\n",
    "\n",
    "    lookback = 10\n",
    "    inputs = np.zeros((len(data) - lookback, lookback, df_input.shape[1]))\n",
    "    labels = np.zeros(len(data) - lookback)\n",
    "\n",
    "    for i in range(lookback, len(data)):\n",
    "        inputs[i - lookback] = data[i - lookback:i]\n",
    "        labels[i - lookback] = data[i, 0]\n",
    "    inputs = inputs.reshape(-1, lookback, df_input.shape[1])\n",
    "    labels = labels.reshape(-1, 1)\n",
    "\n",
    "\n",
    "    if (count < 5):\n",
    "        print(\"---\")\n",
    "        if len(train_x) == 0:\n",
    "            train_x = inputs[:]\n",
    "            print(train_x)\n",
    "            train_y = labels[:]\n",
    "        else:\n",
    "            train_x = np.concatenate((train_x, inputs[:]))\n",
    "            train_y = np.concatenate((train_y, labels[:]))\n",
    "    else:\n",
    "        test_x = inputs\n",
    "        test_y = labels\n",
    "\n",
    "    count = count + 1\n",
    "\n",
    "\n",
    "    # test_portion = int(0.2 * len(inputs))\n",
    "    #\n",
    "    # if len(train_x) == 0:\n",
    "    #     train_x = inputs[:-test_portion]\n",
    "    #     train_y = labels[:-test_portion]\n",
    "    # else:\n",
    "    #     train_x = np.concatenate((train_x, inputs[:-test_portion]))\n",
    "    #     train_y = np.concatenate((train_y, labels[:-test_portion]))\n",
    "    #\n",
    "    # if len(test_x) == 0:\n",
    "    #     test_x = inputs[-test_portion:]\n",
    "    #     test_y = labels[-test_portion:]\n",
    "    # else:\n",
    "    #     test_x = np.concatenate((test_x, inputs[-test_portion:]))\n",
    "    #     test_y = np.concatenate((test_y, labels[-test_portion:]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[1.        ],\n        [0.95075689],\n        [0.92671186],\n        ...,\n        [0.83341703],\n        [0.8125442 ],\n        [0.79517458]],\n\n       [[0.95075689],\n        [0.92671186],\n        [0.91225103],\n        ...,\n        [0.8125442 ],\n        [0.79517458],\n        [0.77879722]],\n\n       [[0.92671186],\n        [0.91225103],\n        [0.88756713],\n        ...,\n        [0.79517458],\n        [0.77879722],\n        [0.76229649]],\n\n       ...,\n\n       [[0.14784123],\n        [0.13705667],\n        [0.11176704],\n        ...,\n        [0.04854059],\n        [0.0371182 ],\n        [0.02569581]],\n\n       [[0.13705667],\n        [0.11176704],\n        [0.10422975],\n        ...,\n        [0.0371182 ],\n        [0.02569581],\n        [0.01844374]],\n\n       [[0.11176704],\n        [0.10422975],\n        [0.08795566],\n        ...,\n        [0.02569581],\n        [0.01844374],\n        [0.01119167]]])"
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "outputs": [
    {
     "data": {
      "text/plain": "(255, 10, 1)"
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_x).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "outputs": [
    {
     "data": {
      "text/plain": "(255, 1)"
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_y).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:, -1]))\n",
    "        return out, h\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "outputs": [],
   "source": [
    "def train(train_loader, learn_rate, hidden_dim=256, EPOCHS=20, model_type=\"GRU\"):\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "\n",
    "    model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        start_time = time.process_time()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            counter += 1\n",
    "            h = h.data\n",
    "            model.zero_grad()\n",
    "\n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            if True:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter,\n",
    "                                                                                           len(train_loader),\n",
    "                                                                                           avg_loss / counter))\n",
    "        current_time = time.process_time()\n",
    "        print(\"Epoch {}/{} Done, Total Loss: {}\".format(epoch, EPOCHS, avg_loss / len(train_loader)))\n",
    "        print(\"Total Time Elapsed: {} seconds\".format(str(current_time - start_time)))\n",
    "        epoch_times.append(current_time - start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(model, test_x, test_y, label_scalers):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.process_time()\n",
    "\n",
    "    inp = torch.from_numpy(np.array(test_x))\n",
    "    labs = torch.from_numpy(np.array(test_y))\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    outputs.append(label_sc.inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "    targets.append(label_sc.inverse_transform(labs.numpy()).reshape(-1))\n",
    "\n",
    "    print(\"Evaluation Time: {}\".format(str(time.process_time() - start_time)))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += np.mean(abs(outputs[i] - targets[i]) / (targets[i] + outputs[i]) / 2) / len(outputs)\n",
    "    print(\"sMAPE: {}%\".format(sMAPE * 100))\n",
    "    return outputs, targets, sMAPE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training of GRU model\n",
      "Epoch 1......Step: 1/7....... Average Loss for Epoch: 0.16193991899490356\n",
      "Epoch 1......Step: 2/7....... Average Loss for Epoch: 0.14811810106039047\n",
      "Epoch 1......Step: 3/7....... Average Loss for Epoch: 0.11964280903339386\n",
      "Epoch 1......Step: 4/7....... Average Loss for Epoch: 0.09798514470458031\n",
      "Epoch 1......Step: 5/7....... Average Loss for Epoch: 0.0877804733812809\n",
      "Epoch 1......Step: 6/7....... Average Loss for Epoch: 0.08066762052476406\n",
      "Epoch 1......Step: 7/7....... Average Loss for Epoch: 0.07449745599712644\n",
      "Epoch 1/20 Done, Total Loss: 0.07449745599712644\n",
      "Total Time Elapsed: 1.109375 seconds\n",
      "Epoch 2......Step: 1/7....... Average Loss for Epoch: 0.0335463210940361\n",
      "Epoch 2......Step: 2/7....... Average Loss for Epoch: 0.03215478267520666\n",
      "Epoch 2......Step: 3/7....... Average Loss for Epoch: 0.032135648652911186\n",
      "Epoch 2......Step: 4/7....... Average Loss for Epoch: 0.03530860738828778\n",
      "Epoch 2......Step: 5/7....... Average Loss for Epoch: 0.03417397402226925\n",
      "Epoch 2......Step: 6/7....... Average Loss for Epoch: 0.032626125030219555\n",
      "Epoch 2......Step: 7/7....... Average Loss for Epoch: 0.030678742166076387\n",
      "Epoch 2/20 Done, Total Loss: 0.030678742166076387\n",
      "Total Time Elapsed: 1.359375 seconds\n",
      "Epoch 3......Step: 1/7....... Average Loss for Epoch: 0.020112061873078346\n",
      "Epoch 3......Step: 2/7....... Average Loss for Epoch: 0.02207378391176462\n",
      "Epoch 3......Step: 3/7....... Average Loss for Epoch: 0.018376480787992477\n",
      "Epoch 3......Step: 4/7....... Average Loss for Epoch: 0.016034065978601575\n",
      "Epoch 3......Step: 5/7....... Average Loss for Epoch: 0.014541885815560818\n",
      "Epoch 3......Step: 6/7....... Average Loss for Epoch: 0.013805977068841457\n",
      "Epoch 3......Step: 7/7....... Average Loss for Epoch: 0.01320861918585641\n",
      "Epoch 3/20 Done, Total Loss: 0.01320861918585641\n",
      "Total Time Elapsed: 1.28125 seconds\n",
      "Epoch 4......Step: 1/7....... Average Loss for Epoch: 0.0009802303975448012\n",
      "Epoch 4......Step: 2/7....... Average Loss for Epoch: 0.0023936989600770175\n",
      "Epoch 4......Step: 3/7....... Average Loss for Epoch: 0.00483631012806048\n",
      "Epoch 4......Step: 4/7....... Average Loss for Epoch: 0.00578928561299108\n",
      "Epoch 4......Step: 5/7....... Average Loss for Epoch: 0.0051158468937501315\n",
      "Epoch 4......Step: 6/7....... Average Loss for Epoch: 0.005193560830472658\n",
      "Epoch 4......Step: 7/7....... Average Loss for Epoch: 0.005829647033741432\n",
      "Epoch 4/20 Done, Total Loss: 0.005829647033741432\n",
      "Total Time Elapsed: 1.5 seconds\n",
      "Epoch 5......Step: 1/7....... Average Loss for Epoch: 0.006639957893639803\n",
      "Epoch 5......Step: 2/7....... Average Loss for Epoch: 0.005125966505147517\n",
      "Epoch 5......Step: 3/7....... Average Loss for Epoch: 0.0038271143954868117\n",
      "Epoch 5......Step: 4/7....... Average Loss for Epoch: 0.0035043831157963723\n",
      "Epoch 5......Step: 5/7....... Average Loss for Epoch: 0.003857167693786323\n",
      "Epoch 5......Step: 6/7....... Average Loss for Epoch: 0.003835242105803142\n",
      "Epoch 5......Step: 7/7....... Average Loss for Epoch: 0.0035188794136047363\n",
      "Epoch 5/20 Done, Total Loss: 0.0035188794136047363\n",
      "Total Time Elapsed: 0.96875 seconds\n",
      "Epoch 6......Step: 1/7....... Average Loss for Epoch: 0.002180539071559906\n",
      "Epoch 6......Step: 2/7....... Average Loss for Epoch: 0.0022986356634646654\n",
      "Epoch 6......Step: 3/7....... Average Loss for Epoch: 0.00282389127338926\n",
      "Epoch 6......Step: 4/7....... Average Loss for Epoch: 0.0030238530598580837\n",
      "Epoch 6......Step: 5/7....... Average Loss for Epoch: 0.0029686188325285913\n",
      "Epoch 6......Step: 6/7....... Average Loss for Epoch: 0.0026085229959183684\n",
      "Epoch 6......Step: 7/7....... Average Loss for Epoch: 0.002388237218838185\n",
      "Epoch 6/20 Done, Total Loss: 0.002388237218838185\n",
      "Total Time Elapsed: 1.125 seconds\n",
      "Epoch 7......Step: 1/7....... Average Loss for Epoch: 0.002916676225140691\n",
      "Epoch 7......Step: 2/7....... Average Loss for Epoch: 0.0026005354011431336\n",
      "Epoch 7......Step: 3/7....... Average Loss for Epoch: 0.002391963809107741\n",
      "Epoch 7......Step: 4/7....... Average Loss for Epoch: 0.001966480922419578\n",
      "Epoch 7......Step: 5/7....... Average Loss for Epoch: 0.0018459148472175003\n",
      "Epoch 7......Step: 6/7....... Average Loss for Epoch: 0.0017424011408972244\n",
      "Epoch 7......Step: 7/7....... Average Loss for Epoch: 0.0018490855083135621\n",
      "Epoch 7/20 Done, Total Loss: 0.0018490855083135621\n",
      "Total Time Elapsed: 0.96875 seconds\n",
      "Epoch 8......Step: 1/7....... Average Loss for Epoch: 0.0012831053463742137\n",
      "Epoch 8......Step: 2/7....... Average Loss for Epoch: 0.001084757677745074\n",
      "Epoch 8......Step: 3/7....... Average Loss for Epoch: 0.000970874447375536\n",
      "Epoch 8......Step: 4/7....... Average Loss for Epoch: 0.0009235074830939993\n",
      "Epoch 8......Step: 5/7....... Average Loss for Epoch: 0.001118107361253351\n",
      "Epoch 8......Step: 6/7....... Average Loss for Epoch: 0.0010449951320576172\n",
      "Epoch 8......Step: 7/7....... Average Loss for Epoch: 0.0010382668780429022\n",
      "Epoch 8/20 Done, Total Loss: 0.0010382668780429022\n",
      "Total Time Elapsed: 1.109375 seconds\n",
      "Epoch 9......Step: 1/7....... Average Loss for Epoch: 0.0008083928842097521\n",
      "Epoch 9......Step: 2/7....... Average Loss for Epoch: 0.0008745519444346428\n",
      "Epoch 9......Step: 3/7....... Average Loss for Epoch: 0.0008003739058040082\n",
      "Epoch 9......Step: 4/7....... Average Loss for Epoch: 0.0008298604807350785\n",
      "Epoch 9......Step: 5/7....... Average Loss for Epoch: 0.000843885273206979\n",
      "Epoch 9......Step: 6/7....... Average Loss for Epoch: 0.0007840335019864142\n",
      "Epoch 9......Step: 7/7....... Average Loss for Epoch: 0.0008179150421970657\n",
      "Epoch 9/20 Done, Total Loss: 0.0008179150421970657\n",
      "Total Time Elapsed: 1.0 seconds\n",
      "Epoch 10......Step: 1/7....... Average Loss for Epoch: 0.0006366992020048201\n",
      "Epoch 10......Step: 2/7....... Average Loss for Epoch: 0.0008545876771677285\n",
      "Epoch 10......Step: 3/7....... Average Loss for Epoch: 0.000859308949050804\n",
      "Epoch 10......Step: 4/7....... Average Loss for Epoch: 0.0008183214667951688\n",
      "Epoch 10......Step: 5/7....... Average Loss for Epoch: 0.0008736121584661305\n",
      "Epoch 10......Step: 6/7....... Average Loss for Epoch: 0.000786325428634882\n",
      "Epoch 10......Step: 7/7....... Average Loss for Epoch: 0.0008215175808540412\n",
      "Epoch 10/20 Done, Total Loss: 0.0008215175808540412\n",
      "Total Time Elapsed: 1.234375 seconds\n",
      "Epoch 11......Step: 1/7....... Average Loss for Epoch: 0.0009958664886653423\n",
      "Epoch 11......Step: 2/7....... Average Loss for Epoch: 0.0008835777989588678\n",
      "Epoch 11......Step: 3/7....... Average Loss for Epoch: 0.0007256941171362996\n",
      "Epoch 11......Step: 4/7....... Average Loss for Epoch: 0.0007738814601907507\n",
      "Epoch 11......Step: 5/7....... Average Loss for Epoch: 0.0007012697984464467\n",
      "Epoch 11......Step: 6/7....... Average Loss for Epoch: 0.0007089852588251233\n",
      "Epoch 11......Step: 7/7....... Average Loss for Epoch: 0.0007919062461171832\n",
      "Epoch 11/20 Done, Total Loss: 0.0007919062461171832\n",
      "Total Time Elapsed: 1.859375 seconds\n",
      "Epoch 12......Step: 1/7....... Average Loss for Epoch: 0.0010088217677548528\n",
      "Epoch 12......Step: 2/7....... Average Loss for Epoch: 0.0007655353401787579\n",
      "Epoch 12......Step: 3/7....... Average Loss for Epoch: 0.0007932643832949301\n",
      "Epoch 12......Step: 4/7....... Average Loss for Epoch: 0.0007887654355727136\n",
      "Epoch 12......Step: 5/7....... Average Loss for Epoch: 0.0008955021388828754\n",
      "Epoch 12......Step: 6/7....... Average Loss for Epoch: 0.0008199570341578996\n",
      "Epoch 12......Step: 7/7....... Average Loss for Epoch: 0.0007620797467617584\n",
      "Epoch 12/20 Done, Total Loss: 0.0007620797467617584\n",
      "Total Time Elapsed: 1.640625 seconds\n",
      "Epoch 13......Step: 1/7....... Average Loss for Epoch: 0.0006415331154130399\n",
      "Epoch 13......Step: 2/7....... Average Loss for Epoch: 0.0005569343047682196\n",
      "Epoch 13......Step: 3/7....... Average Loss for Epoch: 0.0005216552138638993\n",
      "Epoch 13......Step: 4/7....... Average Loss for Epoch: 0.0005066218654974364\n",
      "Epoch 13......Step: 5/7....... Average Loss for Epoch: 0.00047260833089239894\n",
      "Epoch 13......Step: 6/7....... Average Loss for Epoch: 0.0005470534718673056\n",
      "Epoch 13......Step: 7/7....... Average Loss for Epoch: 0.0006358202621673367\n",
      "Epoch 13/20 Done, Total Loss: 0.0006358202621673367\n",
      "Total Time Elapsed: 1.34375 seconds\n",
      "Epoch 14......Step: 1/7....... Average Loss for Epoch: 0.00028522664797492325\n",
      "Epoch 14......Step: 2/7....... Average Loss for Epoch: 0.0006961933249840513\n",
      "Epoch 14......Step: 3/7....... Average Loss for Epoch: 0.0007429859348728011\n",
      "Epoch 14......Step: 4/7....... Average Loss for Epoch: 0.0006876160405226983\n",
      "Epoch 14......Step: 5/7....... Average Loss for Epoch: 0.0005945379816694185\n",
      "Epoch 14......Step: 6/7....... Average Loss for Epoch: 0.0005374689183857603\n",
      "Epoch 14......Step: 7/7....... Average Loss for Epoch: 0.0005144784829878647\n",
      "Epoch 14/20 Done, Total Loss: 0.0005144784829878647\n",
      "Total Time Elapsed: 1.609375 seconds\n",
      "Epoch 15......Step: 1/7....... Average Loss for Epoch: 0.001025096862576902\n",
      "Epoch 15......Step: 2/7....... Average Loss for Epoch: 0.0011471380712464452\n",
      "Epoch 15......Step: 3/7....... Average Loss for Epoch: 0.000933757071228077\n",
      "Epoch 15......Step: 4/7....... Average Loss for Epoch: 0.0008164874598151073\n",
      "Epoch 15......Step: 5/7....... Average Loss for Epoch: 0.0007056629692669958\n",
      "Epoch 15......Step: 6/7....... Average Loss for Epoch: 0.0006587567962318038\n",
      "Epoch 15......Step: 7/7....... Average Loss for Epoch: 0.0006145630821785224\n",
      "Epoch 15/20 Done, Total Loss: 0.0006145630821785224\n",
      "Total Time Elapsed: 1.34375 seconds\n",
      "Epoch 16......Step: 1/7....... Average Loss for Epoch: 0.000648964662104845\n",
      "Epoch 16......Step: 2/7....... Average Loss for Epoch: 0.0004746546328533441\n",
      "Epoch 16......Step: 3/7....... Average Loss for Epoch: 0.000429708743467927\n",
      "Epoch 16......Step: 4/7....... Average Loss for Epoch: 0.00046437331184279174\n",
      "Epoch 16......Step: 5/7....... Average Loss for Epoch: 0.0004205302509944886\n",
      "Epoch 16......Step: 6/7....... Average Loss for Epoch: 0.00042808584597272176\n",
      "Epoch 16......Step: 7/7....... Average Loss for Epoch: 0.0004554742980482323\n",
      "Epoch 16/20 Done, Total Loss: 0.0004554742980482323\n",
      "Total Time Elapsed: 1.09375 seconds\n",
      "Epoch 17......Step: 1/7....... Average Loss for Epoch: 0.0005046103033237159\n",
      "Epoch 17......Step: 2/7....... Average Loss for Epoch: 0.0008356089529115707\n",
      "Epoch 17......Step: 3/7....... Average Loss for Epoch: 0.0006607735898190489\n",
      "Epoch 17......Step: 4/7....... Average Loss for Epoch: 0.0006410834976122715\n",
      "Epoch 17......Step: 5/7....... Average Loss for Epoch: 0.0005790465802419931\n",
      "Epoch 17......Step: 6/7....... Average Loss for Epoch: 0.0006064616851896668\n",
      "Epoch 17......Step: 7/7....... Average Loss for Epoch: 0.0006413998406579984\n",
      "Epoch 17/20 Done, Total Loss: 0.0006413998406579984\n",
      "Total Time Elapsed: 1.25 seconds\n",
      "Epoch 18......Step: 1/7....... Average Loss for Epoch: 0.00023597538529429585\n",
      "Epoch 18......Step: 2/7....... Average Loss for Epoch: 0.0003202926236554049\n",
      "Epoch 18......Step: 3/7....... Average Loss for Epoch: 0.0003882675227941945\n",
      "Epoch 18......Step: 4/7....... Average Loss for Epoch: 0.00043299293247400783\n",
      "Epoch 18......Step: 5/7....... Average Loss for Epoch: 0.0006805445736972615\n",
      "Epoch 18......Step: 6/7....... Average Loss for Epoch: 0.0006263559941241207\n",
      "Epoch 18......Step: 7/7....... Average Loss for Epoch: 0.0005756804499209725\n",
      "Epoch 18/20 Done, Total Loss: 0.0005756804499209725\n",
      "Total Time Elapsed: 1.3125 seconds\n",
      "Epoch 19......Step: 1/7....... Average Loss for Epoch: 0.0007304697064682841\n",
      "Epoch 19......Step: 2/7....... Average Loss for Epoch: 0.0005571867368416861\n",
      "Epoch 19......Step: 3/7....... Average Loss for Epoch: 0.0005033316556364298\n",
      "Epoch 19......Step: 4/7....... Average Loss for Epoch: 0.0005002164398320019\n",
      "Epoch 19......Step: 5/7....... Average Loss for Epoch: 0.0006008545868098735\n",
      "Epoch 19......Step: 6/7....... Average Loss for Epoch: 0.000568683176728276\n",
      "Epoch 19......Step: 7/7....... Average Loss for Epoch: 0.0005796004843432456\n",
      "Epoch 19/20 Done, Total Loss: 0.0005796004843432456\n",
      "Total Time Elapsed: 1.421875 seconds\n",
      "Epoch 20......Step: 1/7....... Average Loss for Epoch: 0.0007914646412245929\n",
      "Epoch 20......Step: 2/7....... Average Loss for Epoch: 0.0009305196290370077\n",
      "Epoch 20......Step: 3/7....... Average Loss for Epoch: 0.0007840364899796745\n",
      "Epoch 20......Step: 4/7....... Average Loss for Epoch: 0.000775228749262169\n",
      "Epoch 20......Step: 5/7....... Average Loss for Epoch: 0.0007195370970293879\n",
      "Epoch 20......Step: 6/7....... Average Loss for Epoch: 0.0006386858246211583\n",
      "Epoch 20......Step: 7/7....... Average Loss for Epoch: 0.0006063358284466501\n",
      "Epoch 20/20 Done, Total Loss: 0.0006063358284466501\n",
      "Total Time Elapsed: 1.390625 seconds\n",
      "Total Training Time: 25.921875 seconds\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "gru_model = train(train_loader, lr, model_type=\"GRU\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Time: 0.03125\n",
      "sMAPE: 0.2748517945354554%\n"
     ]
    }
   ],
   "source": [
    "gru_outputs, targets, gru_sMAPE = evaluate(gru_model, test_x, test_y, label_sc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([0.9152331 , 0.9109752 , 0.90688807, 0.9029217 , 0.8990419 ,\n        0.8952607 , 0.8915334 , 0.8878296 , 0.8840557 , 0.88017267,\n        0.8761983 , 0.87215996, 0.868056  , 0.86402565, 0.8600608 ,\n        0.85614884, 0.8522662 , 0.8484267 , 0.84467304, 0.8410299 ,\n        0.83747315, 0.83409697, 0.8308065 , 0.8275463 , 0.8243592 ,\n        0.82122093, 0.8181056 , 0.81507796, 0.8118055 , 0.8086004 ,\n        0.8055917 , 0.802664  , 0.79970104, 0.7968093 , 0.793918  ,\n        0.79099995, 0.7880301 , 0.7851565 , 0.78237826, 0.7796438 ,\n        0.7646035 ], dtype=float32)]"
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x18657f95ab0>"
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1400x1000 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(gru_outputs[0][-100:], \"-o\", color=\"g\", label=\"Predicted\")\n",
    "plt.plot(targets[0][-100:], color=\"b\", label=\"Actual\")\n",
    "plt.ylabel('soh')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "abb986b297a1e39e4a9784cac1041b65609e2eefd57e07e1d90a430925bc2fc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
